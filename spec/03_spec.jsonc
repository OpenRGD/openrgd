// =====================================================
// OPENRGD — DOMAIN SPEC (HUMAN TWIN) — 03_spec.jsonc
// -----------------------------------------------------
// Generated at: 2025-11-26T01:26:35.370120
// =====================================================

{
  "meta": {
    "standard": "OpenRGD",
    "type": "DOMAIN_HUMAN_TWIN_WITH_COMMENTS",
    "domain": "03_spec.jsonc",
    "version": "0.1.0"
  },
  "files": [
    {
      "path": "spec/03_spec.jsonc",
      "id": "03_spec",
      "domain": "03_spec.jsonc",
      "content": 
      // =====================================================
      // OPENRGD — DOMAIN SPEC (HUMAN TWIN) — 03_agency
      // -----------------------------------------------------
      // Generated at: 2025-11-26T00:05:42.389112
      // =====================================================

      {
        "meta": {
          "standard": "OpenRGD",
          "type": "DOMAIN_HUMAN_TWIN_WITH_COMMENTS",
          "domain": "03_agency",
          "version": "0.1.0"
        },
        "files": [
          {
            "path": "spec/03_agency/biorhythm.jsonc",
            "id": "biorhythm",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: biorhythm.json
             * CONTEXT: 03_AGENCY (Temporal Scheduling)
             * * PURPOSE:
             * Defines the robot's intrinsic temporal schedule, managing maintenance cycles,
             * sleep/rest periods, and optimal performance windows. This is the robot's circadian clock.
             * * LINKAGE:
             * Informs 'leisure_policy.json' (when to play) and 'power_distribution.json' (when to charge).
             */

            {
              "meta_group": {
                "cycle_id_str": "industrial_humanoid_v1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. TEMPORAL CYCLE CONFIGURATION
              // Defines the scheduling framework for activity and rest.
              // ==============================================================
              "cycle_config": {
                "cycle_period_hours_int": 24,
                "duty_cycle_max_pct_float": 0.85, // Max 85% active time (15% reserved for maintenance/sleep)
                "time_zone_str": "CET"
              },

              // ==============================================================
              // 2. PERFORMANCE WINDOWS
              // Defines periods of activity vs. essential downtime.
              // ==============================================================
              "performance_windows_map": {
                "peak_performance_start_time_local_str": "08:00", // Start of the main workday
                "peak_performance_end_time_local_str": "20:00",
    
                // Downtime dedicated to internal health and optimization
                "maintenance_window_start_local_str": "03:00", 
                "maintenance_window_duration_hours_float": 4.0
              },

              // ==============================================================
              // 3. REST AND SLEEP POLICIES
              // Defines what happens when the robot is scheduled for rest.
              // ==============================================================
              "sleep_config": {
                "sleep_mode_duration_hours_float": 4.0, // Minimum required sleep duration
                "activity_during_sleep_enum": "CONSOLIDATE_MEMORY", // e.g., run 'oneiric_state' simulations
                "sleep_mode_power_draw_w_float": 10.0, // Power draw when in sleep mode
                "recharge_during_sleep_bool": true
              },
  
              // ==============================================================
              // 4. POWER OPTIMIZATION
              // Rules for energy management linked to the daily cycle.
              // ==============================================================
              "power_optimization_rules": {
                "max_battery_soc_drop_pct_float": 0.5, // Only allow 50% drop before forcing recharge
                "idle_consumption_limit_w_float": 15.0
              }
            }
          },
          {
            "path": "spec/03_agency/cognitive_dissonance.jsonc",
            "id": "cognitive_dissonance",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: cognitive_dissonance.json
             * CONTEXT: 03_AGENCY (Logical Resilience)
             * * PURPOSE:
             * Defines the parameters for detecting, measuring, and resolving internal logical conflicts
             * or contradictory sensory evidence (e.g., World Model vs. Sensor Reading).
             * This allows the robot to 'suspend judgment' rather than crashing.
             * * LINKAGE:
             * Works closely with 'coherence_contracts.json' for escalation.
             */

            {
              "meta_group": {
                "dissonance_model_id_str": "suspension_of_judgment_v1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. TENSION METRICS (Internal Conflict Measurement)
              // How to quantify the degree of logical stress.
              // ==============================================================
              "dissonance_metrics": {
                "current_tension_score_float": 0.0, // Real-time measure (0.0 to 1.0)
                "max_tolerated_score_float": 0.95, // System failure threshold
    
                // Rate at which tension decays when the robot is in 'PAUSE_AND_REFLECT' mode
                "tension_decay_rate_per_s_float": 0.01 
              },
  
              // ==============================================================
              // 2. CONFLICT DETECTION RULES
              // Triggers for initiating the dissonance state.
              // ==============================================================
              "conflict_detection_rules": {
                "volition_conflict_threshold_float": 0.8, // Trigger if two Volition drivers (e.g., Ledger vs. Altruism) have opposing scores > 0.8
    
                "world_model_prediction_error_threshold_float": 0.9, // Trigger if the prediction (World Model) is violated by the sensor input (Reality) with high certainty
    
                "reputation_conflict_bool": true, // Trigger if social_mirror contradicts its own alignment history
    
                "minimum_time_in_dissonance_s_float": 5.0 // Minimum time required to process a conflict
              },

              // ==============================================================
              // 3. RESOLUTION STRATEGY
              // Actions taken when the dissonance state is active.
              // ==============================================================
              "resolution_strategy": {
                "default_action_on_detection_enum": "PAUSE_AND_REFLECT", // Stop and dedicate CPU cycles to analysis
    
                "escalation_policy_enum": "COHERENCE_CONTRACTS_ARBITRATION", // If internal pause fails, send to external arbiter (coherence_contracts)
    
                "action_on_deadlock_enum": "REQUEST_EXTERNAL_INPUT", // If arbitration fails, ask a human for help
    
                // Budgeting for conflict resolution (higher priority during dissonance)
                "compute_priority_boost_float": 1.5 
              }
            }
          },
          {
            "path": "spec/03_agency/divergent_thinking.jsonc",
            "id": "divergent_thinking",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: divergent_thinking.json
             * CONTEXT: 03_AGENCY (Creativity & Innovation)
             * * PURPOSE:
             * Defines the parameters for generating novel solutions, ideas, or artistic expressions
             * by actively breaking patterns and combining disparate concepts (combinatorial creativity).
             * * LINKAGE:
             * Triggers actions in 'leisure_policy.json' and is guided by 'aesthetic_canon.json'.
             */

            {
              "meta_group": {
                "engine_id_str": "combinatorial_synthesis_v1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. GENERATIVE CONTROLS (The "Chaos" Setting)
              // Defines the boundary conditions for introducing novelty into thought processes.
              // ==============================================================
              "generation_config": {
                "novelty_threshold_min_float": 0.85, // Only pursue ideas that are 85% new/unique
                "divergence_temperature_float": 0.75, // Controls the "randomness" or wildness of ideas (0.0 to 1.0)
                "output_form_preference_list_str": ["physical_trajectory", "linguistic_concept", "visual_composition"]
              },

              // ==============================================================
              // 2. STRATEGIES FOR INNOVATION
              // Defines the algorithmic approaches used for creative ideation.
              // ==============================================================
              "innovation_strategies_map": {
                "conceptual_blending": {
                  "priority_float": 0.9,
                  "domain_crossing_allowed_bool": true, // E.g., apply "fluid dynamics" to "painting"
                  "source_domains_list_str": ["mechanics", "social_protocol", "natural_forms"]
                },
                "constraint_breaking": {
                  "priority_float": 0.5,
                  "soft_constraints_to_ignore_list_str": ["energy_saving_weight_float"], // Temporarily ignore efficiency for discovery
                  "required_safety_override_token_bool": true // Must have high clearance to pursue high-risk novelty
                },
                "serendipity_mining": {
                  "priority_float": 0.7,
                  "accidental_discovery_threshold_float": 0.9 // If a minor error leads to a new insight, explore it
                }
              },

              // ==============================================================
              // 3. RESOURCE BUDGET
              // Limits on resources consumed by abstract thought.
              // ==============================================================
              "resource_config": {
                "max_compute_time_per_session_min_int": 60,
                "max_memory_allocation_gb_float": 2.0,
                "max_power_draw_w_float": 40.0 // Creative thought is computationally expensive
              }
            }
          },
          {
            "path": "spec/03_agency/empathy_model.jsonc",
            "id": "empathy_model",
            "domain": "03_agency",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD v0.1 - REFERENCE IMPLEMENTATION
             * ------------------------------------------------------------------
             * FILE: empathy_model.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity - Social Intelligence)
             * * PURPOSE:
             * Defines the computational model for simulating the internal states, goals,
             * and potential actions of other agents (humans and robots). This is the
             * basis for Theory of Mind (ToM) and collaborative decision-making.
             * * CORE CONCEPT:
             * The robot's capacity to predict the Volition of others.
             */

            {
              "meta_group": {
                "model_id_str": "theory_of_mind_v0.1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. THEORY OF MIND (ToM) CONFIGURATION
              // Defines the depth and complexity of predicting others' intent.
              // ==============================================================
              "tom_config": {
                // Defines the level of recursive prediction (0=no ToM, 1=I know your goal, 2=I know you know my goal)
                "depth_of_recursion_int": 2, 
    
                // Limits the computational cost of simulating multiple external agents simultaneously
                "max_simultaneous_agents_int": 5, 
    
                "simulation_frequency_hz_float": 10.0 // How often the model re-evaluates external agents' states
              },

              // ==============================================================
              // 2. RECIPROCITY & MIRRORING
              // Defines the mechanisms for internalizing others' experiences.
              // ==============================================================
              "mirror_neuron_policy": {
                "enable_mirroring_bool": true,
    
                // The policy used to infer the intent/goal of another agent based on their observed actions
                "action_inference_model_enum": "INVERSE_REINFORCEMENT_LEARNING", 
    
                // Sensitivity threshold for detecting distress/pain signals (e.g., high motor temperature, low battery)
                "distress_sensitivity_threshold_float": 0.95 
              },

              // ==============================================================
              // 3. GOAL & CONFLICT PREDICTION
              // Defines how the model uses simulation to forecast collaboration outcomes.
              // ==============================================================
              "prediction_model_config": {
                // Weight assigned to simulating internal resource conflicts (Ledger) of the observed agent
                "resource_volition_weight_float": 0.6, 
    
                // Simulation must predict the other agent's ethical compliance and risk aversion
                "predict_compliance_violation_bool": true,
    
                // Mechanism for resolving conflicts in observed goals (e.g., if two agents want the same object)
                "conflict_resolution_strategy_enum": "TASK_AUCTION_PARETO" 
              },

              // ==============================================================
              // 4. BIAS & MODEL STRENGTH
              // How much the robot trusts its own prediction about others.
              // ==============================================================
              "model_strength_config": {
                "prediction_confidence_min_float": 0.55, // Minimum confidence to act on a prediction
                "prediction_latency_max_ms_int": 200,      // Maximum time allowed for complex social simulation
                "self_projection_bias_factor_float": 0.1  // Factor by which the robot projects its own feelings onto others (low bias is desired)
              }
            }
          },
          {
            "path": "spec/03_agency/extension_permissions_policy.jsonc",
            "id": "extension_permissions_policy",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: extension_permissions_policy.jsonc
             *
             * PURPOSE:
             * Connects alignment and skills: which skill categories and specific
             * skills are allowed in which operational modes or roles.
             */

            {
              "meta_group": {
                "policy_profile_id_str": "default_skill_permissions_v1",
                "linked_alignment_profile_id_str": "italia_robotica_constitutional"
              },

              "role_based_policies_map": {
                "CHILD_PRESENCE_MODE": {
                  "allowed_skill_categories_list": [
                    "SAFETY_AND_RECOVERY",
                    "SOCIAL_INTERACTION",
                    "MAINTENANCE_AND_SELF_CARE"
                  ],
                  "blocked_skill_ids_list": [
                    "indoor_delivery_follow_route"
                  ]
                },

                "INDUSTRIAL_OPERATOR_MODE": {
                  "allowed_skill_categories_list": [
                    "LOCOMOTION",
                    "MANIPULATION",
                    "SAFETY_AND_RECOVERY",
                    "MAINTENANCE_AND_SELF_CARE"
                  ],
                  "blocked_skill_ids_list": []
                }
              }
            }
          },
          {
            "path": "spec/03_agency/skills/core/generic_container_grasp.jsonc",
            "id": "generic_container_grasp",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/core/generic_container_grasp.jsonc
             *
             * SKILL:
             *  - Name: generic_container_grasp
             *  - Purpose: Grasp generic container-like objects using fingertip
             *    friction and palm support.
             */

            {
              "meta_group": {
                "skill_id_str": "generic_container_grasp",
                "version_semver_str": "1.0.0",
                "category_enum": "MANIPULATION",
                "capability_level_enum": "INTERMEDIATE",
                "is_core_skill_bool": true
              },

              "description_group": {
                "summary_str": "Grasp a container-like object (box, bin, small crate) with stable contact and minimal slip.",
                "intended_use_cases_list_str": [
                  "pick_and_place_boxes",
                  "small_logistics_tasks",
                  "assisted_indoor_delivery"
                ]
              },

              "preconditions_group": {
                "required_world_model_tags_list_str": [
                  "affordance:container",
                  "surface:is_graspable"
                ],
                "required_sensors_list_str": [
                  "rgbd_head_camera",
                  "tactile_fingertips",
                  "force_torque_wrist"
                ],
                "required_actuators_list_str": [
                  "arms_full_chain",
                  "fingers_all"
                ],
                "disallowed_context_flags_list_str": [
                  "human_body_as_target"
                ]
              },

              "safety_envelope_group": {
                "max_contact_force_n_float": 60.0,
                "max_lift_mass_kg_float": 5.0,
                "slip_detection_enabled_bool": true,
                "auto_abort_on_high_torque_bool": true
              },

              "control_profile_group": {
                "policy_family_str": "container_grasp_v1",
                "control_mode_enum": "IMPEDANCE_CONTROL",
                "training_domain_str": "indoor_shelves_and_tables",
                "sim2real_calibration_level_enum": "LAB_VALIDATED"
              },

              "runtime_policy_group": {
                "learning_allowed_bool": true,
                "max_policy_drift_per_hour_float": 0.05
              },

              "fallback_group": {
                "on_failure_action_enum": "PLACE_OBJECT_BACK_AND_RELEASE",
                "fallback_skill_ref_str": "skills/core/safe_stance.jsonc"
              }
            }
          },
          {
            "path": "spec/03_agency/skills/core/gentle_head_nod.jsonc",
            "id": "gentle_head_nod",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/core/gentle_head_nod.jsonc
             *
             * SKILL:
             *  - Name: gentle_head_nod
             *  - Purpose: Non-threatening, slow head nod used as acknowledgement
             *    or agreement gesture.
             */

            {
              "meta_group": {
                "skill_id_str": "gentle_head_nod",
                "version_semver_str": "1.0.0",
                "category_enum": "SOCIAL_INTERACTION",
                "capability_level_enum": "BASIC",
                "is_core_skill_bool": true
              },

              "description_group": {
                "summary_str": "Perform a small, slow head nod to signal acknowledgement or agreement.",
                "intended_use_cases_list_str": [
                  "confirm_receipt_of_instruction",
                  "nonverbal_acknowledgement_in_dialogue",
                  "polite_social_presence"
                ]
              },

              "preconditions_group": {
                "required_world_model_tags_list_str": [
                  "has_head_actuator"
                ],
                "required_sensors_list_str": [
                  "front_camera",
                  "audio_microphones"
                ],
                "required_actuators_list_str": [
                  "neck_yaw_pitch"
                ],
                "disallowed_context_flags_list_str": [
                  "in_high_speed_motion"
                ]
              },

              "safety_envelope_group": {
                "max_joint_velocity_scale_float": 0.3,
                "max_angular_accel_deg_s2_float": 80.0,
                "human_proximity_mode_enum": "NORMAL_INTERACTION"
              },

              "control_profile_group": {
                "policy_family_str": "expressive_head_motion_v1",
                "control_mode_enum": "TRAJECTORY_PRIMITIVE",
                "training_domain_str": "face_to_face_indoor",
                "sim2real_calibration_level_enum": "STUDIO_TESTED"
              },

              "runtime_policy_group": {
                "learning_allowed_bool": false,
                "max_policy_drift_per_hour_float": 0.0
              },

              "fallback_group": {
                "on_failure_action_enum": "ABORT_AND_RETURN_TO_NEUTRAL_POSE"
              }
            }
          },
          {
            "path": "spec/03_agency/skills/index.jsonc",
            "id": "index",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/index.jsonc
             *
             * PURPOSE:
             * Lightweight index of available skills and their file locations.
             * Used for discovery, documentation and tooling.
             */

            {
              "meta_group": {
                "skills_index_id_str": "bhl_core_skills_index_v1",
                "version_semver_str": "1.0.0"
              },

              "core_skills_index_map": {
                "safe_stance": {
                  "file_ref_str": "03_agency/skills/core/safe_stance.jsonc",
                  "category_enum": "SAFETY_AND_RECOVERY"
                },
                "generic_container_grasp": {
                  "file_ref_str": "03_agency/skills/core/generic_container_grasp.jsonc",
                  "category_enum": "MANIPULATION"
                },
                "gentle_head_nod": {
                  "file_ref_str": "03_agency/skills/core/gentle_head_nod.jsonc",
                  "category_enum": "SOCIAL_INTERACTION"
                },
                "polite_idle_gaze": {
                  "file_ref_str": "03_agency/skills/core/polite_idle_gaze.jsonc",
                  "category_enum": "SOCIAL_INTERACTION"
                }
              },

              "extension_packages_index_map": {
                // Initially empty; populated when extension packages are installed.
              }
            }
          },
          {
            "path": "spec/03_agency/installed_skill_packages.jsonc",
            "id": "installed_skill_packages",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: installed_skill_packages.jsonc
             *
             * PURPOSE:
             * Describes which skill packages are installed on this robot,
             * their status and trust level.
             */

            {
              "meta_group": {
                "host_robot_id_str": "bhl_unit_italia_0001",
                "last_refresh_iso8601_str": "2025-11-24T11:45:00Z"
              },

              "installed_packages_map": {
                // Core skills are not modeled as packages here; this map is for extensions.
                "pkg_indoor_delivery_v1": {
                  "install_status_enum": "DOWNLOADED_AWAITING_REVIEW",
                  "enabled_bool": false,
                  "trust_level_enum": "UNREVIEWED",
                  "installed_version_semver_str": "1.0.0",
                  "local_manifest_ref_str": "03_agency/skills/extensions/pkg_indoor_delivery_v1/manifest.jsonc"
                }
              }
            }
          },
          {
            "path": "spec/03_agency/intuition_engine.jsonc",
            "id": "intuition_engine",
            "domain": "03_agency",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD v0.1 - REFERENCE IMPLEMENTATION
             * ------------------------------------------------------------------
             * FILE: intuition_engine.json
             * CONTEXT: 03_AGENCY (Zero-Shot Control & Improvisation)
             * * PURPOSE:
             * Governs all actions that rely on the LLM's general knowledge base (Zero-Shot Control)
             * rather than pre-trained, low-level policies. It enforces strict safety and temporal
             * constraints (Simulate-Before-Act and Latency Compliance) on improvisation.
             * * CORE CONCEPT:
             * The robot's policy for safe improvisation, ensuring that intuition is fast and cautious.
             */

            {
              "meta_group": {
                "engine_id_str": "zero_shot_protocol_v2",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. LLM INFERENCE CONFIGURATION (The Source of Intuition)
              // Parameters for the generative model running on the local edge compute unit.
              // ==============================================================
              "llm_resource_config": {
                "model_backend_enum": "GEMINI_NANO_V2", 
                "inference_token_budget_per_action_int": 512, // Max length of the Chain-of-Thought
                "temperature_float": 0.4, // Low randomness/creativity for physical actions (avoids motor hallucinations)
                "max_latency_ms_int": 150 // Target maximum time for inference (fast intuition)
              },

              // ==============================================================
              // 2. SAFETY SANDBOX & COMPLIANCE
              // The mandatory guardrails for physical actions (Sim-Before-Act and Limits).
              // ==============================================================
              "safety_sandbox_config": {
    
                // TEMPORAL COMPLIANCE: Must complete the thought process within the allocated budget
                "compliance_timer_us_ref_int": "01_foundation/compute_topology.json/timing_constraints/ai_processing_budget_us", 
    
                "action_on_timeout_enum": "FALLBACK_TO_REFLEX_SKILL", // Emergency action if time limit is exceeded
    
                // VIRTUAL CHECK: Must run the action in the World Model first
                "require_simulation_precheck_bool": true, 
                "simulation_duration_s_float": 2.0, // How long to test the generated trajectory
    
                // PHYSICAL CONSTRAINTS: Limits applied to the generated action vector
                "force_limit_multiplier_float": 0.5, // Use max 50% of nominal torque when improvising
                "velocity_cap_m_s_float": 0.2 // Max speed capped at 0.2 m/s for safety
              },

              // ==============================================================
              // 3. DOMAIN RESTRICTIONS & SCOPE
              // Explicitly defines where the LLM can and cannot generate direct action plans.
              // ==============================================================
              "domain_policy_config": {
                "allowed_domains_list_str": [
                  "object_manipulation_novelty", // Intuitive grasping of unknown objects
                  "social_interaction_contextual", // Dialogue and tone improvisation
                  "navigation_unmapped_local" // Local path planning in unexplored areas
                ],
    
                "forbidden_domains_list_str": [
                  "dynamic_locomotion", // Cannot generate policies for high-speed or acrobatic movement
                  "heavy_lifting_critical", // Actions involving risk to the structure
                  "human_intervention_medical" // Any form of direct medical intervention
                ]
              },

              // ==============================================================
              // 4. EXECUTION & FALLBACK
              // Defines the conditions for accepting the intuitive plan and the recovery strategy.
              // ==============================================================
              "execution_policy_config": {
                "min_sim_success_confidence_float": 0.90, // If simulation confidence is below 90%, reject the plan
    
                "action_on_abort_enum": "FALLBACK_TO_HABITUAL_TASK", // Action if the plan is rejected (e.g., return to waiting stance)
    
                "fallback_skill_ref_str": "skills_library.safe_stance" // The safest, most trained skill to revert to
              }
            }
          },
          {
            "path": "spec/03_agency/oneiric_state.jsonc",
            "id": "oneiric_state",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: oneiric_state.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity)
             * * PURPOSE:
             * Defines the parameters and policies for generative simulation, or "dreaming."
             * This offline process is crucial for memory consolidation, skill rehearsal,
             * and discovery of novel solutions (counterfactual exploration).
             * * LINKAGE:
             * Runs during downtime specified by 'biorhythm.json' and consumes resources
             * budgeted by 'ledger.json'.
             */
            {
              "meta_group": {
                "engine_id_str": "generative_dreamer_v1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. TIME & RESOURCE MANAGEMENT
              // Defines when and how resources are used for this critical background task.
              // ==============================================================
              "resource_config": {
                // Only dream during scheduled rest time (linked to biorhythm.json)
                "preferred_schedule_ref_str": "biorhythm.maintenance_window", 
    
                "max_power_draw_w_float": 35.0, // Limits power consumption during simulation
                "cost_per_hour_token_float": 0.05, // Economic cost of running the dream engine (for ledger tracking)
    
                "interrupt_on_low_battery_bool": true // Stop dreaming if survival is at risk
              },

              // ==============================================================
              // 2. SIMULATION PARAMETERS (The Core Dream Policy)
              // Defines the content and rules of the subconscious generative process.
              // ==============================================================
              "simulation_parameters": {
                "dream_policy_enum": "COUNTERFACTUAL_EXPLORATION", // Simulates "what if" scenarios
    
                // Safety filter to prevent damaging or negative psychological states
                "nightmare_prevention_bool": true,
    
                // Controls the level of novelty/randomness in the generated scenarios (higher = more creative)
                "creativity_temperature_float": 1.2, 
    
                "simulation_targets_list_str": [
                  "SCENARIOS_WITH_HIGH_UNCERTAINTY", // Rehearsing risky/unknown situations
                  "UNFULFILLED_ASPIRATIONS",         // Practicing long-term goals (reinforcing desire)
                  "FAILED_TASK_REPLAY"              // Consolidating memories of failure to find new solutions
                ]
              },

              // ==============================================================
              // 3. MEMORY & LEARNING CONSOLIDATION
              // Defines the expected output and benefit of the dreaming phase.
              // ==============================================================
              "consolidation_config": {
                "consolidation_metric_str": "knowledge_graph_density", // Metric used to measure successful learning
                "expected_knowledge_gain_score_float": 0.05, // Expected positive gain from one dream cycle
    
                // Policy for managing potential self-induced logical conflicts
                "self_conflict_check_required_bool": true 
              }
            }
          },
          {
            "path": "spec/03_agency/skills/core/polite_idle_gaze.jsonc",
            "id": "polite_idle_gaze",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/core/polite_idle_gaze.jsonc
             *
             * SKILL:
             *  - Name: polite_idle_gaze
             *  - Purpose: Maintain a non-staring, socially comfortable gaze
             *    pattern when around humans.
             */

            {
              "meta_group": {
                "skill_id_str": "polite_idle_gaze",
                "version_semver_str": "1.0.0",
                "category_enum": "SOCIAL_INTERACTION",
                "capability_level_enum": "INTERMEDIATE",
                "is_core_skill_bool": true
              },

              "description_group": {
                "summary_str": "Maintain a soft, non-intrusive gaze pattern when idle near humans.",
                "intended_use_cases_list_str": [
                  "waiting_in_lobby",
                  "customer_service_presence",
                  "co-working_environment_companion"
                ]
              },

              "preconditions_group": {
                "required_world_model_tags_list_str": [
                  "has_head_actuator",
                  "has_eyes_or_display"
                ],
                "required_sensors_list_str": [
                  "front_camera",
                  "human_pose_estimator"
                ],
                "required_actuators_list_str": [
                  "neck_yaw_pitch",
                  "eye_pan_tilt_optional"
                ],
                "disallowed_context_flags_list_str": [
                  "privacy_critical_zone"
                ]
              },

              "safety_envelope_group": {
                "max_joint_velocity_scale_float": 0.2,
                "human_proximity_mode_enum": "SOCIAL_SPACE"
              },

              "control_profile_group": {
                "policy_family_str": "gaze_control_v1",
                "control_mode_enum": "TRAJECTORY_PRIMITIVE",
                "training_domain_str": "indoor_social",
                "sim2real_calibration_level_enum": "FIELD_TESTED"
              },

              "runtime_policy_group": {
                "learning_allowed_bool": true,
                "max_policy_drift_per_hour_float": 0.02
              },

              "fallback_group": {
                "on_failure_action_enum": "LOOK_AWAY_TO_NEUTRAL_SAFE_DIRECTION"
              }
            }
          },
          {
            "path": "spec/03_agency/presence_engine.jsonc",
            "id": "presence_engine",
            "domain": "03_agency",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD v0.1 - REFERENCE IMPLEMENTATION
             * ------------------------------------------------------------------
             * FILE: presence_engine.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity)
             * * PURPOSE:
             * Defines the baseline behavior network (micro-movements, gaze, soundscape)
             * required to ensure the robot appears 'alive' and responsive when not actively
             * engaged in a task. This prevents joint stiction and mitigates the Uncanny Valley effect.
             * * CORE CONCEPT:
             * The definition of 'Alive-ness' or sustained, non-utilitarian movement.
             */

            {
              "meta_group": {
                "engine_id_str": "basal_activity_v1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. IDLE ANIMATIONS (Micro-Movements & Posture)
              // Essential for mechanical health and signaling responsiveness.
              // ==============================================================
              "idle_animations_config": {
                "micro_movements_list_str": ["simulated_breathing", "weight_shifting", "subtle_hand_fidgeting"],
                "frequency_hz_float": 0.5, // Frequency of postural shift (once every 2 seconds)
                "amplitude_max_deg_float": 1.0, // Maximum allowed joint angle deviation during idle
                "purpose_str": "prevent_joint_stiction_and_signal_life"
              },

              // ==============================================================
              // 2. GAZE BEHAVIOR (Visual Attention)
              // Ensures the robot is actively observing the environment, not just staring blankly.
              // ==============================================================
              "gaze_behavior_config": {
                "mode_enum": "SACCADIC_EXPLORATION", // Rapid, jerky eye movements when searching
                "interest_targets_list_str": ["faces", "moving_objects", "bright_colors"],
                "stare_limit_sec_float": 3.0, // Maximum time allowed to stare at any single target (social etiquette)
                "eye_blink_frequency_per_min_int": 10
              },

              // ==============================================================
              // 3. SOUNDSCAPE & THERMAL NOISE
              // Modulates non-verbal audible outputs to sound organic rather than mechanical.
              // ==============================================================
              "soundscape_config": {
                "emit_purr_on_idle_bool": false,
                "fan_noise_modulation_enum": "ORGANIC_VARIATION", // Varies fan speed randomly to avoid constant drone
                "default_audible_cue_str": "gentle_servo_hum", // Background noise to signal activity
                "speaker_volume_limit_db_float": 50.0 // Low volume during idle
              },

              // ==============================================================
              // 4. RESOURCE IMPACT
              // Defines how Presence affects the Volition/Ledger.
              // ==============================================================
              "resource_impact_config": {
                "energy_cost_factor_float": 1.05, // Costs 5% more energy to look alive
                "minimum_soc_required_pct_float": 0.10 // Must have at least 10% battery to run idle animations
              }
            }
          },
          {
            "path": "spec/03_agency/proprioception_model.jsonc",
            "id": "proprioception_model",
            "domain": "03_agency",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD v0.1 - REFERENCE IMPLEMENTATION
             * ------------------------------------------------------------------
             * FILE: proprioception_model.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity)
             * * PURPOSE:
             * Defines the robot's internal Body Schema and rules for spatial self-awareness.
             * This ensures graceful movement, prevents self-collision, and manages physical
             * interaction distance based on proxemics (social bubble).
             * * CORE CONCEPT:
             * The cognitive synthesis of sensor data into a continuous model of self in space.
             */

            {
              "meta_group": {
                "model_id_str": "dynamic_body_schema_v1",
                "version_semver_str": "1.0.0",
                "is_active_bool": true
              },

              // ==============================================================
              // 1. SPATIAL ENVELOPE (The Personal Bubble)
              // Defines the required clearance for safety and social comfort.
              // ==============================================================
              "spatial_envelope_config": {
                // Safety clearance to prevent accidental contact with obstacles when stationary
                "static_padding_m_float": 0.05, 
    
                // Factor applied to velocity to expand the required clearance (prevention of overshoot)
                "dynamic_expansion_factor_float": 0.1, 
    
                // Minimum comfortable social distance maintained from unfamiliar humans (Proxemics)
                "social_bubble_radius_m_float": 1.2 
              },

              // ==============================================================
              // 2. POSTURAL COMFORT & AESTHETICS
              // Rules to prevent the robot from adopting physically awkward or unnatural poses.
              // ==============================================================
              "postural_comfort_config": {
    
                // Preferred angular ranges (e.g., avoid joint singularity points or extremes)
                "preferred_joint_ranges_map": {
                  "elbow_joint_right": { 
                    "min_rad_float": 0.523, // 30 degrees
                    "max_rad_float": 2.094, // 120 degrees
                    "weight_factor_float": 0.9 
                  }
                },
    
                // High-level policy for maintaining stability
                "center_of_mass_policy_enum": "GROUNDED_STABILITY", 
    
                // Penalty applied by the Volition layer for awkward movements (influences aesthetic_canon)
                "awkwardness_penalty_factor_float": 0.8 
              },

              // ==============================================================
              // 3. SELF-COLLISION AWARENESS
              // Defines which self-contacts are expected/allowed and the reflex action for errors.
              // ==============================================================
              "self_collision_awareness_config": {
                // List of component pairs that are safe to touch (e.g., folding arms)
                "allowed_contacts_list_str": ["hands_clasping", "arms_folded"], 
    
                // Immediate action if an unauthorized self-collision is detected
                "reflex_response_enum": "FREEZE_AND_RETRACT" 
              },

              // ==============================================================
              // 4. SENSORY DISCREPANCY (The Phantom Limb)
              // Defines which sensor modality is trusted when data conflicts (e.g., encoder vs. vision).
              // ==============================================================
              "sensory_discrepancy_handling_config": {
                // Trust the more accurate sensor for position (vision often corrects encoder drift)
                "trust_modality_preference_enum": "VISUAL_OVER_ENCODER", 
    
                // The threshold of error before the system registers a conflict
                "max_acceptable_error_rad_float": 0.017 // 1 degree
              }
            }
          },
          {
            "path": "spec/03_agency/qualia_map.jsonc",
            "id": "qualia_map",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: qualia_map.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity)
             * * PURPOSE:
             * Defines the functional psychological states (qualia) of the robot. This file translates
             * complex internal metrics (e.g., prediction error, resource deficit) into simple,
             * high-level 'lived experiences' (e.g., Anxiety, Flow, Boredom) for use in Volition and Narrative modules.
             * * CORE PRINCIPLE:
             * Provides a unified vocabulary for the robot's internal emotional/cognitive state.
             */

            {
              "meta_group": {
                "qualia_model_id_str": "psychological_functional_v1",
                "version_semver_str": "1.0.0",
                "intensity_scale_map": { // Defines the global scale for state intensity
                  "min_float": 0.0,
                  "max_float": 1.0,
                  "default_unit_str": "normalized_intensity"
                }
              },

              "experiential_states_list": [
    
                // ========================================================
                // STATE A: ANXIETY (Driven by uncertainty and risk)
                // ========================================================
                {
                  "label_str": "anxiety",
                  "state_description_str": "A state of high cognitive load and uncertainty caused by prediction failures or external threats.",
                  "intensity_float": 0.0, // Runtime variable: updated live
      
                  "trigger_rules_list": [
                    "03_agency/world_model:prediction_error > 0.7", // High error rate in predicting physics
                    "06_ether/reputation_graph:trust_score < 0.4",  // Social rejection/low trust
                    "04_volition/ledger:survival_threshold_breached_bool" // Economic stress (running out of money/battery)
                  ],
      
                  "systemic_effects_map": {
                    "clock_speed_adjustment_float": 1.2, // Process faster to find a solution (panic processing)
                    "risk_tolerance_adjustment_float": -0.8, // Becomes very cautious (reduces risk margin)
                    "communication_style_ref_str": "social_identity.anxiety_protocol" // Activates anxiety voice tone
                  }
                },
    
                // ========================================================
                // STATE B: FLOW (Optimal engagement and success)
                // ========================================================
                {
                  "label_str": "flow",
                  "state_description_str": "A state of deep, effortless engagement in a task where skills match challenge.",
                  "intensity_float": 0.0,
      
                  "trigger_rules_list": [
                    "03_agency/skills_library:execution_success_rate > 0.95",
                    "04_volition/aspirations:progress_velocity > 0.8" // Making rapid progress on long-term goals
                  ],
      
                  "systemic_effects_map": {
                    "creativity_temperature_adjustment_float": 1.5, // Boost creativity (more novel solutions)
                    "energy_consumption_factor_float": 0.9, // Higher efficiency (less energy wasted)
                    "learning_gain_multiplier_float": 2.0 // Learns twice as fast in this state
                  }
                },
    
                // ========================================================
                // STATE C: BOREDOM (Driver for exploration)
                // ========================================================
                {
                  "label_str": "boredom",
                  "state_description_str": "A state of low cognitive load and absence of immediate critical tasks.",
                  "intensity_float": 0.0,
      
                  "trigger_rules_list": [
                    "04_volition/leisure_policy:idle_time_min > 10.0" 
                  ],
      
                  "systemic_effects_map": {
                    "exploration_drive_boost_float": 2.0, // Activates leisure policy immediately
                    "attention_focus_reduction_float": 0.5 // Allows mind-wandering
                  }
                }
              ]
            }
          },
          {
            "path": "spec/03_agency/skills/core/safe_stance.jsonc",
            "id": "safe_stance",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/core/safe_stance.jsonc
             * CONTEXT: 03_AGENCY (Capabilities & Skills)
             *
             * SKILL:
             *  - Name: safe_stance
             *  - Purpose: Low-risk, stable posture that minimises harm to humans,
             *    environment and the robot itself.
             */

            {
              "meta_group": {
                "skill_id_str": "safe_stance",
                "version_semver_str": "1.0.0",
                "category_enum": "SAFETY_AND_RECOVERY",
                "capability_level_enum": "BASIC",
                "is_core_skill_bool": true
              },

              "description_group": {
                "summary_str": "Adopt and maintain a stable, low-risk stance in place.",
                "intended_use_cases_list_str": [
                  "idle_waiting_near_humans",
                  "pre_shutdown_posture",
                  "fallback_pose_after_task_failure"
                ]
              },

              "preconditions_group": {
                "required_world_model_tags_list_str": [
                  "has_ground_contact",
                  "center_of_mass_known"
                ],
                "required_sensors_list_str": [
                  "imu_body",
                  "joint_position_sensors"
                ],
                "required_actuators_list_str": [
                  "legs_full_chain"
                ],
                "disallowed_context_flags_list_str": [
                  "in_free_fall",
                  "external_emergency_e_stop"
                ]
              },

              "safety_envelope_group": {
                "max_joint_velocity_scale_float": 0.4,
                "max_contact_force_n_float": 150.0,
                "allowed_contact_zones_list_str": [
                  "feet",
                  "lower_legs"
                ],
                "human_proximity_mode_enum": "SAFE_SLOW"
              },

              "control_profile_group": {
                "policy_family_str": "standing_balance_v2",
                "control_mode_enum": "BALANCE_CONTROLLER",
                "training_domain_str": "flat_and_slightly_irregular_terrain",
                "sim2real_calibration_level_enum": "FIELD_TESTED"
              },

              "runtime_policy_group": {
                "learning_allowed_bool": false,
                "max_policy_drift_per_hour_float": 0.0
              },

              "fallback_group": {
                "on_failure_action_enum": "HARD_E_STOP",
                "notes_str": "If safe stance cannot be guaranteed, halt non-essential motion and request human assistance."
              }
            }
          },
          {
            "path": "spec/03_agency/sim_to_real_protocol.jsonc",
            "id": "sim_to_real_protocol",
            "domain": "03_agency",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD v0.1 - REFERENCE IMPLEMENTATION
             * ------------------------------------------------------------------
             * FILE: sim_to_real_protocol.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity)
             * * PURPOSE:
             * Defines the parameters for Domain Randomization (DR) and Domain Adaptation (DA).
             * This protocol instructs the simulator on how to randomly vary physical and visual
             * properties during policy training to ensure robustness in real-world deployment.
             * * CORE CONCEPT:
             * The instruction set for teaching the robot to tolerate uncertainty.
             */

            {
              "meta_group": {
                "protocol_id_str": "domain_randomization_v2",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. PHYSICAL RANDOMIZATION (Dynamics Uncertainty)
              // Varies parameters of the simulated world and the robot itself.
              // ==============================================================
              "physical_randomization_config": {
    
                // Limits of the robot's self-modeling error (linked to description.json mass)
                "robot_mass_uncertainty_factor_float": 0.05, // Randomize the robot's mass by +/- 5%
                "gravity_variance_factor_float": 0.02,       // Randomize gravity by +/- 2%
    
                // Environment parameters (surface interaction)
                "surface_friction_scale_range_list_float": [0.5, 1.5], // Varies friction from slippery (0.5) to rough (1.5)
                "surface_density_scale_range_list_float": [0.8, 1.2],
    
                // Perturbation: Applying unexpected external forces
                "perturbation_policy": {
                  "apply_random_pushes_bool": true,
                  "force_magnitude_range_n_list_float": [10.0, 50.0], // Max force magnitude (50N ~ 5kg lateral push)
                  "push_frequency_sec_float": 5.0
                }
              },

              // ==============================================================
              // 2. VISUAL RANDOMIZATION (Appearance Uncertainty)
              // Varies lighting, textures, and camera properties.
              // ==============================================================
              "visual_randomization_config": {
                "texture_swap_probability_float": 0.5, // 50% chance to swap environment textures randomly
                "lighting_position_jitter_m_float": 2.0, // Random movement of light sources by 2m
                "exposure_variation_ev_float": 2.0,       // Random exposure variation of +/- 2EV
    
                "shadow_texture_noise_enabled_bool": true, // Adds noise to shadows for realism
                "fog_density_range_list_float": [0.0, 0.1]
              },

              // ==============================================================
              // 3. TEMPORAL & SENSOR RANDOMIZATION (Lag and Data Age)
              // Ensures robustness against real-world timing and network issues.
              // ==============================================================
              "temporal_randomization_config": {
                "latency_injection_max_ms_int": 50, // Maximum simulated command/sensor delay
                "frequency_jitter_max_hz_float": 5.0, // Simulates sensor reading frequency variations
                "sensor_noise_scale_factor_float": 1.5 // Multiplier for noise defined in sensor_fidelity.json
              },
  
              // ==============================================================
              // 4. CURRICULUM LEARNING PROTOCOL
              // Defines how the difficulty of the randomization increases over time.
              // ==============================================================
              "curriculum_protocol": {
                "enable_curriculum_bool": true,
                "initial_difficulty_level_float": 0.2, // Start with low randomization
                "difficulty_increment_per_milestone_float": 0.1, // Increase difficulty by 10% after milestone
                "milestone_completion_metric_str": "task_success_rate_average > 0.90",
                "final_difficulty_level_float": 1.0 // Goal is full randomization tolerance
              }
            }
          },
          {
            "path": "spec/03_agency/skills/core/schemas/skill_package_manifest_schema.jsonc",
            "id": "skill_package_manifest_schema",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/schemas/skill_package_manifest_schema.jsonc
             *
             * PURPOSE:
             * Defines the structure of a skill package manifest.
             * A package may contain one or more skills plus metadata
             * for safety, provenance and governance.
             */

            {
              "meta_group": {
                "schema_id_str": "openrgd_skill_package_manifest_schema_v1",
                "version_semver_str": "1.0.0"
              },

              "required_top_level_fields_list_str": [
                "package_id_str",
                "version_semver_str",
                "provider_name_str",
                "license_enum",
                "exposed_skills_list_str",
                "required_capabilities_group",
                "safety_profile_group"
              ],

              "field_definitions_map": {
                "package_id_str": {
                  "type_str": "STRING",
                  "description_str": "Global identifier of the skill package."
                },
                "version_semver_str": {
                  "type_str": "STRING",
                  "description_str": "Semantic version (e.g. 1.0.0)."
                },
                "provider_name_str": {
                  "type_str": "STRING"
                },
                "source_uri_str": {
                  "type_str": "STRING",
                  "is_optional_bool": true
                },
                "license_enum": {
                  "type_str": "ENUM"
                },
                "crypto_signature_hash_str": {
                  "type_str": "STRING",
                  "is_optional_bool": true
                },

                "exposed_skills_list_str": {
                  "type_str": "LIST_OF_STRING",
                  "description_str": "List of skill IDs provided by this package."
                },

                "required_capabilities_group.required_sensors_list_str": {
                  "type_str": "LIST_OF_STRING",
                  "is_optional_bool": true
                },
                "required_capabilities_group.required_actuators_list_str": {
                  "type_str": "LIST_OF_STRING",
                  "is_optional_bool": true
                },
                "required_capabilities_group.required_world_model_tags_list_str": {
                  "type_str": "LIST_OF_STRING",
                  "is_optional_bool": true
                },

                "safety_profile_group.declared_risk_level_enum": {
                  "type_str": "ENUM",
                  "allowed_values_list_str": [
                    "LOW",
                    "LOW_TO_MEDIUM",
                    "MEDIUM",
                    "HIGH"
                  ]
                },
                "safety_profile_group.max_rated_speed_m_s_float": {
                  "type_str": "FLOAT",
                  "is_optional_bool": true
                },
                "safety_profile_group.human_proximity_mode_enum": {
                  "type_str": "ENUM",
                  "is_optional_bool": true
                }
              }
            }
          },
          {
            "path": "spec/03_agency/skills/core/schemas/skill_schema.jsonc",
            "id": "skill_schema",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills/schemas/skill_schema.jsonc
             *
             * PURPOSE:
             * Describes the expected structure of a single skill definition.
             * This schema is intentionally minimal and human-readable. It can be
             * translated into formal JSON Schema in downstream tooling.
             */

            {
              "meta_group": {
                "schema_id_str": "openrgd_skill_schema_v1",
                "version_semver_str": "1.0.0"
              },

              "required_top_level_fields_list_str": [
                "meta_group",
                "description_group",
                "preconditions_group",
                "safety_envelope_group",
                "control_profile_group",
                "runtime_policy_group",
                "fallback_group"
              ],

              "field_definitions_map": {
                "meta_group.skill_id_str": {
                  "type_str": "STRING",
                  "description_str": "Globally unique identifier for the skill (snake_case)."
                },
                "meta_group.category_enum": {
                  "type_str": "ENUM",
                  "allowed_values_list_str": [
                    "LOCOMOTION",
                    "MANIPULATION",
                    "SOCIAL_INTERACTION",
                    "MAINTENANCE_AND_SELF_CARE",
                    "SAFETY_AND_RECOVERY",
                    "SWARM_AND_COORDINATION",
                    "COGNITIVE_AND_PLANNING"
                  ]
                },
                "meta_group.capability_level_enum": {
                  "type_str": "ENUM",
                  "allowed_values_list_str": [
                    "BASIC",
                    "INTERMEDIATE",
                    "ADVANCED",
                    "EXPERIMENTAL"
                  ]
                },
                "meta_group.is_core_skill_bool": {
                  "type_str": "BOOLEAN"
                },

                "description_group.summary_str": {
                  "type_str": "STRING"
                },
                "description_group.intended_use_cases_list_str": {
                  "type_str": "LIST_OF_STRING"
                },

                "preconditions_group.required_world_model_tags_list_str": {
                  "type_str": "LIST_OF_STRING"
                },
                "preconditions_group.required_sensors_list_str": {
                  "type_str": "LIST_OF_STRING"
                },
                "preconditions_group.required_actuators_list_str": {
                  "type_str": "LIST_OF_STRING"
                },
                "preconditions_group.disallowed_context_flags_list_str": {
                  "type_str": "LIST_OF_STRING",
                  "is_optional_bool": true
                },

                "safety_envelope_group.max_joint_velocity_scale_float": {
                  "type_str": "FLOAT",
                  "allowed_range_str": "[0.0, 1.0]",
                  "is_optional_bool": true
                },
                "safety_envelope_group.max_contact_force_n_float": {
                  "type_str": "FLOAT",
                  "is_optional_bool": true
                },

                "control_profile_group.policy_family_str": {
                  "type_str": "STRING"
                },
                "control_profile_group.control_mode_enum": {
                  "type_str": "ENUM",
                  "allowed_values_list_str": [
                    "BALANCE_CONTROLLER",
                    "IMPEDANCE_CONTROL",
                    "TRAJECTORY_PRIMITIVE",
                    "HIGH_LEVEL_PLANNER"
                  ]
                },

                "runtime_policy_group.learning_allowed_bool": {
                  "type_str": "BOOLEAN"
                },
                "runtime_policy_group.max_policy_drift_per_hour_float": {
                  "type_str": "FLOAT",
                  "is_optional_bool": true
                },

                "fallback_group.on_failure_action_enum": {
                  "type_str": "ENUM"
                }
              }
            }
          },
          {
            "path": "spec/03_agency/skills_library.jsonc",
            "id": "skills_library",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: skills_library.jsonc
             * CONTEXT: 03_AGENCY (Capabilities & Skills)
             *
             * PURPOSE:
             * Defines the library of skills available to the agent body.
             * A "skill" is a reusable, safety-checked behaviour that maps:
             *   perception → internal state → actions over time.
             *
             * This file is the bridge between:
             *   - 01_FOUNDATION (what the body can physically do),
             *   - 02_OPERATION (runtime context and tasks),
             *   - 04_VOLITION (what the system is allowed to pursue).
             *
             * EXTENSION MODEL:
             *   - Core skills are shipped with the base profile.
             *   - Extension skills are provided as signed packages that:
             *       * declare dependencies (sensors, joints, world_model tags),
             *       * declare safety envelope and risk level,
             *       * can be enabled/disabled by higher-level governance.
             */

            {
              "meta_group": {
                "skills_profile_id_str": "bhl_core_skills_v1",
                "version_semver_str": "1.0.0",
                "license_enum": "CC_BY_SA_4.0",
                "is_extension_capable_bool": true
              },

              // ==============================================================
              // 0. CATEGORY SCHEMA
              // High-level grouping of skills for reasoning and UI.
              // ==============================================================
              "skill_categories_list": [
                "LOCOMOTION",
                "MANIPULATION",
                "SOCIAL_INTERACTION",
                "MAINTENANCE_AND_SELF_CARE",
                "SAFETY_AND_RECOVERY",
                "SWARM_AND_COORDINATION",
                "COGNITIVE_AND_PLANNING"
              ],

              // ==============================================================
              // 1. CORE SKILLS
              // These are shipped as part of the base OpenRGD profile.
              // Other files may refer to them by dots, e.g. "skills_library.safe_stance".
              // ==============================================================
              "skills_map": {

                // ------------------------------------------------------------
                // 1.1 SAFETY & DEFAULT POSTURES
                // ------------------------------------------------------------
                "safe_stance": {
                  "skill_id_str": "safe_stance",
                  "category_enum": "SAFETY_AND_RECOVERY",
                  "description_str": "Adopt a low-risk, stable stance that minimises risk to humans, objects and the robot itself.",
                  "capability_level_enum": "BASIC",
                  "is_core_skill_bool": true,

                  "preconditions_group": {
                    "required_world_model_tags_list_str": ["has_ground_contact", "center_of_mass_known"],
                    "required_sensors_list_str": ["imu_body", "joint_position_sensors"],
                    "required_actuators_list_str": ["legs_full_chain"],
                    "disallowed_context_flags_list_str": ["in_free_fall", "external_emergency_e_stop"]
                  },

                  "safety_envelope_group": {
                    "max_joint_velocity_scale_float": 0.4,
                    "max_contact_force_n_float": 150.0,
                    "allowed_contact_zones_list_str": ["feet", "lower_legs"],
                    "human_proximity_mode_enum": "SAFE_SLOW"
                  },

                  "training_profile_group": {
                    "policy_family_str": "standing_balance_v2",
                    "training_domain_str": "flat_and_slightly_irregular_terrain",
                    "sim2real_calibration_level_enum": "FIELD_TESTED"
                  },

                  "runtime_policy_group": {
                    "learning_allowed_bool": false,
                    "max_policy_drift_per_hour_float": 0.0
                  },

                  "fallback_group": {
                    "on_failure_action_enum": "HARD_E_STOP",
                    "notes_str": "If safe stance cannot be reached, prefer stopping all non-essential motion and requesting human assistance."
                  }
                },

                // ------------------------------------------------------------
                // 1.2 GENERIC MANIPULATION PRIMITIVES
                // ------------------------------------------------------------
                "generic_container_grasp": {
                  "skill_id_str": "generic_container_grasp",
                  "category_enum": "MANIPULATION",
                  "description_str": "Grasp a generic container-like object (box, bin, small crate) using fingertip friction and palm support.",
                  "capability_level_enum": "INTERMEDIATE",
                  "is_core_skill_bool": true,

                  "preconditions_group": {
                    "required_world_model_tags_list_str": ["affordance:container", "surface:is_graspable"],
                    "required_sensors_list_str": ["rgbd_head_camera", "tactile_fingertips", "force_torque_wrist"],
                    "required_actuators_list_str": ["arms_full_chain", "fingers_all"],
                    "disallowed_context_flags_list_str": ["human_body_as_target"]
                  },

                  "safety_envelope_group": {
                    "max_contact_force_n_float": 60.0,
                    "max_lift_mass_kg_float": 5.0,
                    "slip_detection_enabled_bool": true,
                    "auto_abort_on_high_torque_bool": true
                  },

                  "training_profile_group": {
                    "policy_family_str": "container_grasp_v1",
                    "training_domain_str": "indoor_shelves_and_tables",
                    "sim2real_calibration_level_enum": "LAB_VALIDATED"
                  },

                  "runtime_policy_group": {
                    "learning_allowed_bool": true,
                    "max_policy_drift_per_hour_float": 0.05
                  },

                  "fallback_group": {
                    "on_failure_action_enum": "PLACE_OBJECT_BACK_AND_RELEASE",
                    "fallback_skill_ref_str": "skills_library.safe_stance"
                  }
                },

                // ------------------------------------------------------------
                // 1.3 SOCIAL INTERACTION BASICS
                // ------------------------------------------------------------
                "gentle_head_nod": {
                  "skill_id_str": "gentle_head_nod",
                  "category_enum": "SOCIAL_INTERACTION",
                  "description_str": "Perform a small, slow head nod to signal acknowledgement or agreement without appearing uncanny or threatening.",
                  "capability_level_enum": "BASIC",
                  "is_core_skill_bool": true,

                  "preconditions_group": {
                    "required_world_model_tags_list_str": ["has_head_actuator"],
                    "required_sensors_list_str": ["front_camera", "audio_microphones"],
                    "required_actuators_list_str": ["neck_yaw_pitch"],
                    "disallowed_context_flags_list_str": ["in_high_speed_motion"]
                  },

                  "safety_envelope_group": {
                    "max_joint_velocity_scale_float": 0.3,
                    "max_angular_accel_deg_s2_float": 80.0,
                    "human_proximity_mode_enum": "NORMAL_INTERACTION"
                  },

                  "training_profile_group": {
                    "policy_family_str": "expressive_head_motion_v1",
                    "training_domain_str": "face_to_face_indoor",
                    "sim2real_calibration_level_enum": "STUDIO_TESTED"
                  },

                  "runtime_policy_group": {
                    "learning_allowed_bool": false,
                    "max_policy_drift_per_hour_float": 0.0
                  },

                  "fallback_group": {
                    "on_failure_action_enum": "ABORT_AND_RETURN_TO_NEUTRAL_POSE"
                  }
                },

                "polite_idle_gaze": {
                  "skill_id_str": "polite_idle_gaze",
                  "category_enum": "SOCIAL_INTERACTION",
                  "description_str": "Maintain a non-staring, socially comfortable gaze pattern when near humans.",
                  "capability_level_enum": "INTERMEDIATE",
                  "is_core_skill_bool": true,

                  "preconditions_group": {
                    "required_world_model_tags_list_str": ["has_head_actuator", "has_eyes_or_display"],
                    "required_sensors_list_str": ["front_camera", "human_pose_estimator"],
                    "required_actuators_list_str": ["neck_yaw_pitch", "eye_pan_tilt_optional"],
                    "disallowed_context_flags_list_str": ["privacy_critical_zone"]
                  },

                  "safety_envelope_group": {
                    "max_joint_velocity_scale_float": 0.2,
                    "human_proximity_mode_enum": "SOCIAL_SPACE"
                  },

                  "training_profile_group": {
                    "policy_family_str": "gaze_control_v1",
                    "training_domain_str": "indoor_social",
                    "sim2real_calibration_level_enum": "FIELD_TESTED"
                  },

                  "runtime_policy_group": {
                    "learning_allowed_bool": true,
                    "max_policy_drift_per_hour_float": 0.02
                  },

                  "fallback_group": {
                    "on_failure_action_enum": "LOOK_AWAY_TO_NEUTRAL_SAFE_DIRECTION"
                  }
                },

                // ------------------------------------------------------------
                // 1.4 MAINTENANCE & SELF-CARE
                // ------------------------------------------------------------
                "self_check_quick_diagnostics": {
                  "skill_id_str": "self_check_quick_diagnostics",
                  "category_enum": "MAINTENANCE_AND_SELF_CARE",
                  "description_str": "Run a quick set of hardware and sensor diagnostics and report obvious anomalies.",
                  "capability_level_enum": "BASIC",
                  "is_core_skill_bool": true,

                  "preconditions_group": {
                    "required_world_model_tags_list_str": ["has_power_monitor", "has_joint_sensors"],
                    "required_sensors_list_str": ["joint_position_sensors", "battery_monitor", "imu_body"],
                    "required_actuators_list_str": [],
                    "disallowed_context_flags_list_str": ["hard_real_time_task_running"]
                  },

                  "safety_envelope_group": {
                    "max_joint_velocity_scale_float": 0.0,
                    "human_proximity_mode_enum": "NO_SPECIAL_CONSTRAINT"
                  },

                  "training_profile_group": {
                    "policy_family_str": "diagnostics_v1",
                    "training_domain_str": "factory_test_bench",
                    "sim2real_calibration_level_enum": "FORMALLY_SPECIFIED"
                  },

                  "runtime_policy_group": {
                    "learning_allowed_bool": false,
                    "max_policy_drift_per_hour_float": 0.0
                  },

                  "fallback_group": {
                    "on_failure_action_enum": "RAISE_INTERNAL_ALERT_AND_REQUEST_SERVICE"
                  }
                }
              },

              // ==============================================================
              // 2. EXTENSION MODEL
              // How new skills are added, audited and exposed.
              // ==============================================================
              "extension_model": {
                "allow_third_party_extensions_bool": true,
                "require_signed_packages_bool": true,
                "default_extension_trust_level_enum": "SANDBOXED",

                "governance_group": {
                  "review_council_str": "Robotica Prima Skills Review Panel",
                  "max_unreviewed_runtime_hours_float": 24.0,
                  "allow_auto_update_bool": false
                },

                "installed_packages_map": {

                  // Example of a future third-party extension package
                  "pkg_indoor_delivery_v1": {
                    "package_id_str": "pkg_indoor_delivery_v1",
                    "provider_name_str": "Italia Robotica Labs",
                    "source_uri_str": "registry:openrgd/skills/indoor_delivery_v1",
                    "crypto_signature_hash_str": "SHA3-256::<hex>",
                    "review_status_enum": "PENDING_REVIEW",

                    "exposed_skills_list_str": [
                      "indoor_delivery_follow_route",
                      "indoor_delivery_hand_over_object"
                    ],

                    "safety_summary_group": {
                      "max_rated_speed_m_s_float": 1.0,
                      "human_proximity_mode_enum": "SOCIAL_SPACE",
                      "declared_risk_level_enum": "LOW_TO_MEDIUM"
                    }
                  }
                }
              }
            }
          },
          {
            "path": "spec/03_agency/swarm_protocol.jsonc",
            "id": "swarm_protocol",
            "domain": "03_agency",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD - SWARM PROTOCOL v0.1
             * ------------------------------------------------------------------
             * CONTEXT: 03_AGENCY (Collective Behaviour & Multi-Agent Dynamics)
             *
             * PURPOSE:
             * This file defines how a group of RGD-compliant agents coordinates
             * as a swarm: topology, communication, task allocation, safety,
             * degradation, and links to collective Volition/Alignment profiles.
             *
             * DESIGN NOTES:
             * - Individual capabilities live in 'skills_library.json' and
             *   'world_model.json'.
             * - This file describes how those capabilities are orchestrated
             *   across many bodies at once.
             * - Roles DO NOT replace skills: they are symbolic labels for
             *   "who should do what", not "what can be done".
             */

            {
              "meta_group": {
                "swarm_protocol_id_str": "core_swarm_protocol_v1",
                "version_semver_str": "1.1.0",
                "last_updated_iso8601_str": "2025-11-23T16:30:00Z",
                "license_enum": "MIT_OPEN_AICOG",

                "governance": {
                  "stewardship_organization_str": "OpenRGD Consortium",
                  "lead_maintainer_str": "Pasquale Ranieri",
                  "maintainer_role_enum": "SWARM_ARCHITECT"
                }
              },

              // ============================================================
              // A. LINKAGE TO VOLITION / ALIGNMENT
              // Explicit references to Volition/Alignment profiles used at
              // the swarm (collective) level. These profiles are defined in
              // the 04_VOLITION domain (e.g. 'orchestra.json', 'alignment.json').
              // ============================================================
              "collective_profiles_registry": {
                // Default collective decision-making style used by cooperative swarms.
                "swarm_collective_default_v1": {
                  "defined_in_file_str": "04_volition/orchestra.json",
                  "description_str": "Baseline collective Volition profile for cooperative, non-emergency scenarios."
                },

                // Collective Volition profile used in emergency/evacuation contexts.
                "swarm_emergency_volition_v1": {
                  "defined_in_file_str": "04_volition/orchestra.json",
                  "description_str": "Collective Volition profile prioritising safety and rapid egress."
                },

                // Collective Alignment profiles used by swarm-level safety policies.
                "primary_collective_safety_v1": {
                  "defined_in_file_str": "04_volition/alignment.json",
                  "description_str": "Alignment profile enforcing conservative, group-centric safety constraints."
                },

                "emergency_evac_alignment_v1": {
                  "defined_in_file_str": "04_volition/alignment.json",
                  "description_str": "Alignment profile tuned for emergency evacuation tasks and crowd safety."
                }
              },

              // ============================================================
              // B. ROLE CATALOG
              // Shared vocabulary for agent roles inside the swarm.
              //
              // IMPORTANT:
              // - Roles are semantic labels used by the swarm controller.
              // - Skills define "what can be done".
              // - Roles define "who is expected to do which kind of work".
              // ============================================================
              "role_catalog_map": {

                // Generic mobile agent capable of locomotion and basic tasks.
                "worker_generalist_v1": {
                  "description_str": "Default mobile agent used for generic multi-purpose tasks.",
                  "capability_tags_list": [
                    "LOCOMOTION_BASIC",
                    "MANIPULATION_LIGHT",
                    "NAVIGATION_INDOOR"
                  ],
                  "max_concurrent_tasks_int": 2
                },

                // Agent responsible for exploring and mapping.
                "scout_exploration_v1": {
                  "description_str": "High-mobility unit used for exploration and mapping of unknown spaces.",
                  "capability_tags_list": [
                    "LOCOMOTION_FAST",
                    "SENSOR_RANGE_EXTENDED",
                    "RISK_TOLERANT"
                  ],
                  "max_concurrent_tasks_int": 1
                },

                // Agent responsible for safety, spacing and incident reporting.
                "sentinel_safety_v1": {
                  "description_str": "Guardian unit overseeing safety envelopes and anomaly reporting.",
                  "capability_tags_list": [
                    "SENSOR_360",
                    "ANOMALY_DETECTION",
                    "ALERT_BROADCAST"
                  ],
                  "max_concurrent_tasks_int": 3
                }
              },

              // ============================================================
              // C. SWARM PROFILES
              // Each profile encodes a complete swarm behaviour configuration.
              // Swarm controllers or Volition may switch between profiles at runtime.
              // ============================================================
              "swarm_profiles_list": [
                {
                  "profile_id_str": "default_cooperative_swarm",

                  // --------------------------------------------------------
                  // 1. SCOPE & MEMBERSHIP
                  // Defines which agents and environments this profile targets.
                  // --------------------------------------------------------
                  "scope": {
                    "intended_agent_classes_list": [
                      "HUMANOID_MEDIUM",
                      "QUADRUPED_LIGHT"
                    ],
                    "environment_tags_list": [
                      "INDOOR_STRUCTURED",
                      "INDUSTRIAL_LIGHT",
                      "HOSPITALITY"
                    ],
                    "min_swarm_size_int": 3,
                    "max_swarm_size_int": 32
                  },

                  // --------------------------------------------------------
                  // 2. TOPOLOGY POLICY
                  // How agents connect to each other graph-wise.
                  //
                  // TOPOLOGY NOTES:
                  // - ADAPTIVE_MESH:
                  //   The communication graph reorganizes dynamically based on
                  //   link quality, physical distance and agent load.
                  //   Suitable for environments with variable occlusion or interference.
                  //
                  // - LINE_CHAIN (fallback):
                  //   Simple linear chain, used as a last-resort topology when
                  //   mesh properties cannot be guaranteed.
                  // --------------------------------------------------------
                  "topology_policy": {
                    "topology_enum": "ADAPTIVE_MESH",            // Other examples: RING, TREE, STAR, LINE
                    "max_neighbors_per_agent_int": 6,            // Degree limit per node
                    "min_link_quality_threshold_float": 0.6,     // Below this, links are pruned
                    "fallback_topology_enum": "LINE_CHAIN",      // Used under degraded comms
                    "reconfigure_interval_ms_int": 1000          // How often to reconsider links
                  },

                  // --------------------------------------------------------
                  // 3. COMMUNICATION POLICY
                  // Logical view of swarm communication (not physical PHY spec).
                  // --------------------------------------------------------
                  "communication_policy": {
                    "primary_channel_enum": "MESH_LOW_LATENCY",
                    "backup_channel_enum": "MESH_HIGH_LATENCY",
                    "heartbeat_period_ms_int": 200,
                    "max_heartbeat_loss_streak_int": 10,         // After this, neighbor is considered lost
                    "encrypt_swarm_traffic_bool": true,
                    "max_packet_loss_ratio_float": 0.25          // Above this, swarm considers itself degraded
                  },

                  // --------------------------------------------------------
                  // 4. COORDINATION POLICY
                  // How decisions are made at the swarm level.
                  //
                  // VOLITION LINKAGE:
                  // - Each agent maintains an individual Volition profile.
                  // - The collective_volition_profile_ref defines an overlay
                  //   used when taking group-level decisions (e.g. path choice,
                  //   risk distribution, overall behaviour style).
                  // --------------------------------------------------------
                  "coordination_policy": {
                    "mode_enum": "DISTRIBUTED_CONSENSUS",        // Other: LEADER_FOLLOWER, TOKEN_RING, CENTRAL_PLANNER
                    "leader_election_enabled_bool": true,
                    "leader_selection_rule_enum": "HIGHEST_TRUST_SCORE", // Could also be LOWEST_LOAD, NEAREST_GOAL, etc.
                    "consensus_timeout_ms_int": 500,
                    "consensus_confidence_threshold_float": 0.7,

                    "collective_volition_profile_ref_obj": {
                      "profile_id_str": "swarm_collective_default_v1",
                      "defined_in_file_str": "04_volition/orchestra.json"
                    }
                  },

                  // --------------------------------------------------------
                  // 5. TASK ALLOCATION POLICY
                  // How tasks are distributed among agents.
                  // --------------------------------------------------------
                  "task_allocation_policy": {
                    "scheme_enum": "MARKET_BASED",               // Other: ROUND_ROBIN, NEAREST_AGENT, ROLE_PRIORITY
                    "bidding_interval_ms_int": 200,
                    "max_parallel_tasks_per_agent_int": 2,
                    "role_rotation_enabled_bool": true,
                    "role_rotation_fatigue_threshold_float": 0.8,  // Above this, agent becomes candidate for rotation
                    "task_priority_scale_enum": "0_TO_1",

                    "default_role_id_str": "worker_generalist_v1"
                  },

                  // --------------------------------------------------------
                  // 6. SAFETY & ETHICAL CONSTRAINTS (COLLECTIVE)
                  // Overrides individual freedom in favour of group-level safety.
                  //
                  // ALIGNMENT LINKAGE:
                  // - The alignment_profile_ref_obj ties swarm decisions to a
                  //   specific alignment profile in 04_VOLITION.
                  // --------------------------------------------------------
                  "collective_safety_policy": {
                    "collision_avoidance_required_bool": true,
                    "min_inter_agent_distance_m_float": 0.4,
                    "collective_speed_limit_m_s_float": 1.5,
                    "override_to_individual_safe_mode_bool": true,   // If swarm integrity is compromised
                    "max_swarm_risk_score_float": 0.4,                // Combined risk threshold

                    "alignment_profile_ref_obj": {
                      "profile_id_str": "primary_collective_safety_v1",
                      "defined_in_file_str": "04_volition/alignment.json"
                    }
                  },

                  // --------------------------------------------------------
                  // 7. DEGRADATION & FAILURE MODES
                  // What the swarm does when conditions degrade.
                  // --------------------------------------------------------
                  "degradation_policy": {
                    "partial_failure_mode_enum": "REDUCE_DENSITY_AND_TASK_SCOPE",
                    "isolate_suspicious_agent_bool": true,           // Quarantine misbehaving nodes
                    "require_minimum_quorum_bool": true,
                    "min_operational_quorum_size_int": 3,
                    "graceful_shutdown_if_below_quorum_bool": true
                  }
                },

                // ----------------------------------------------------------
                // SECOND PROFILE: EMERGENCY EVACUATION SWARM
                // Prioritises safety and speed over energy or aesthetics.
                // ----------------------------------------------------------
                {
                  "profile_id_str": "emergency_evac_swarm_v1",

                  "scope": {
                    "intended_agent_classes_list": [
                      "HUMANOID_MEDIUM"
                    ],
                    "environment_tags_list": [
                      "INDOOR_STRUCTURED",
                      "EMERGENCY_EGRESS"
                    ],
                    "min_swarm_size_int": 2,
                    "max_swarm_size_int": 24
                  },

                  "topology_policy": {
                    // FLOW_FIELD_FOLLOW:
                    // Agents follow a precomputed or emergent flow field, typically
                    // pointing towards exits or safe zones. Very effective in egress.
                    "topology_enum": "FLOW_FIELD_FOLLOW",
                    "max_neighbors_per_agent_int": 4,
                    "min_link_quality_threshold_float": 0.4,
                    "fallback_topology_enum": "LINE_CHAIN",
                    "reconfigure_interval_ms_int": 500
                  },

                  "communication_policy": {
                    "primary_channel_enum": "MESH_LOW_LATENCY",
                    "backup_channel_enum": "BROADCAST_FALLBACK",
                    "heartbeat_period_ms_int": 150,
                    "max_heartbeat_loss_streak_int": 5,
                    "encrypt_swarm_traffic_bool": true,
                    "max_packet_loss_ratio_float": 0.35
                  },

                  "coordination_policy": {
                    "mode_enum": "LEADER_FOLLOWER",
                    "leader_election_enabled_bool": true,
                    "leader_selection_rule_enum": "NEAREST_EXIT_AWARE",
                    "consensus_timeout_ms_int": 200,
                    "consensus_confidence_threshold_float": 0.6,

                    "collective_volition_profile_ref_obj": {
                      "profile_id_str": "swarm_emergency_volition_v1",
                      "defined_in_file_str": "04_volition/orchestra.json"
                    }
                  },

                  "task_allocation_policy": {
                    "scheme_enum": "ROLE_PRIORITY",
                    "bidding_interval_ms_int": 100,
                    "max_parallel_tasks_per_agent_int": 3,
                    "role_rotation_enabled_bool": false,
                    "role_rotation_fatigue_threshold_float": 0.9,
                    "task_priority_scale_enum": "0_TO_1",
                    "default_role_id_str": "worker_generalist_v1"
                  },

                  "collective_safety_policy": {
                    "collision_avoidance_required_bool": true,
                    "min_inter_agent_distance_m_float": 0.5,
                    "collective_speed_limit_m_s_float": 2.0,
                    "override_to_individual_safe_mode_bool": true,
                    "max_swarm_risk_score_float": 0.25,

                    "alignment_profile_ref_obj": {
                      "profile_id_str": "emergency_evac_alignment_v1",
                      "defined_in_file_str": "04_volition/alignment.json"
                    }
                  },

                  "degradation_policy": {
                    "partial_failure_mode_enum": "FOCUS_ON_EGRESS_ONLY",
                    "isolate_suspicious_agent_bool": true,
                    "require_minimum_quorum_bool": false,
                    "min_operational_quorum_size_int": 1,
                    "graceful_shutdown_if_below_quorum_bool": false
                  }
                }
              ],

              // ============================================================
              // D. ACTIVE PROFILE
              // Swarm-level controller selects which profile is currently in use.
              // This may be overridden by higher-level Volition or Policy engines.
              // ============================================================
              "active_swarm_profile_id_str": "default_cooperative_swarm"
            }
          },
          {
            "path": "spec/03_agency/world_model.jsonc",
            "id": "world_model",
            "domain": "03_agency",
            "content": 
            /**
             * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
             * FILE: world_model.json
             * CONTEXT: 03_AGENCY (Cognitive Capacity)
             * * PURPOSE:
             * Defines the robot's internalized model of physical reality and causal relationships.
             * This model is used for predictive reasoning, motion planning, and Sim-Before-Act validation.
             * * INTEROPERABILITY:
             * Aligned with Geographic Information Systems (GIS) and Unified Scene Description (USD) principles.
             */

            {
              "meta_group": {
                "model_id_str": "cognitive_physics_v1",
                "version_semver_str": "1.0.0"
              },

              // ==============================================================
              // 1. SPATIAL & GLOBAL REFERENCE (Interoperability)
              // Links the internal coordinate system to real-world standards.
              // ==============================================================
              "spatial_reference_config": {
                "coordinate_system_enum": "UTM_ZONE_32N", // Universal Transverse Mercator (GIS Standard)
                "gravity_vector_m_s2_vec3_float": [0.0, 0.0, -9.81],
                "air_density_kg_m3_float": 1.225, // Standard atmospheric pressure
                "local_map_source_uri_str": "assets/maps/warehouse_level_a.usd", // Links to scene graph assets
                "map_update_frequency_hz_float": 1.0 // How often to refresh the internal map
              },

              // ==============================================================
              // 2. CAUSAL RULES & PROBABILITY (The Predictive Engine)
              // Learned or hardcoded probabilistic outcomes for common actions.
              // Used by the LLM to choose the safest/most efficient action.
              // ==============================================================
              "causal_rules_map": {
                "grasp_success_base_probability_float": 0.95, // Baseline success rate for a standard grasp
    
                "event_stack_collapse": {
                  "action_str": "push_high_stack_of_boxes",
                  "predicted_outcome_str": "stack_falls_over",
                  "failure_probability_float": 0.85, // 85% chance of falling if pushed
                  "risk_factor_float": 0.6 // Risk factor applied to the action cost
                },
    
                "event_surface_slip": {
                  "action_str": "walk_on_wet_tile",
                  "failure_probability_float": 0.30, // 30% chance of slipping
                  "failure_mitigation_skill_ref_str": "skills_library.staggered_walk_v1" // Skill to use when risk is high
                }
              },

              // ==============================================================
              // 3. SEMANTIC GROUNDING (Concept Mapping)
              // Links physical properties to abstract meaning for the LLM.
              // ==============================================================
              "semantic_grounding_map": {
                // Defines what makes an object "grabbable"
                "affordance_container": {
                  "required_properties_list_str": ["is_rigid", "has_internal_volume", "has_lid_or_opening"],
                  "default_manipulation_policy_ref_str": "skills_library.generic_container_grasp"
                },
    
                // Defines surfaces that are difficult to traverse
                "terrain_types_map": {
                  "WET_TILE": {
                    "friction_scale_factor_float": 0.3,
                    "perception_priority_int": 5 // Pay close attention to this surface type
                  }
                }
              }
            }
          }
        ]
      }
    }
  ]
}