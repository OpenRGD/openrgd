// =====================================================
// OPENRGD — DOMAIN SPEC (HUMAN TWIN) — 06_spec.jsonc
// -----------------------------------------------------
// Generated at: 2025-11-26T01:26:35.993983
// =====================================================

{
  "meta": {
    "standard": "OpenRGD",
    "type": "DOMAIN_HUMAN_TWIN_WITH_COMMENTS",
    "domain": "06_spec.jsonc",
    "version": "0.1.0"
  },
  "files": [
    {
      "path": "spec/06_spec.jsonc",
      "id": "06_spec",
      "domain": "06_spec.jsonc",
      "content": 
      // =====================================================
      // OPENRGD — DOMAIN SPEC (HUMAN TWIN) — 06_ether
      // -----------------------------------------------------
      // Generated at: 2025-11-26T00:05:42.700972
      // =====================================================

      {
        "meta": {
          "standard": "OpenRGD",
          "type": "DOMAIN_HUMAN_TWIN_WITH_COMMENTS",
          "domain": "06_ether",
          "version": "0.1.0"
        },
        "files": [
          {
            "path": "spec/06_ether/civilization_manifesto.jsonc",
            "id": "civilization_manifesto",
            "domain": "06_ether",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD - CIVILIZATION MANIFESTO v0.1
             * ------------------------------------------------------------------
             * CONTEXT: 06_ETHER (Collective Teleology & Civilizational Intent)
             *
             * PURPOSE:
             * This file encodes the long-horizon goals, cultural values and
             * historical phases of an artificial civilization. It is not a
             * task list, but a teleological scaffold: a shared "why" that
             * extends beyond any individual agent's lifetime.
             *
             * DESIGN NOTES:
             * - Individual aspirations live in '04_volition/aspirations.json'.
             * - This file expresses trans-generational ambitions and values.
             * - Swarm and Federation components (reputation, consensus, compute)
             *   should interpret this file as "civilizational north-star".
             */

            {
              "meta_group": {
                "civilization_manifesto_id_str": "robotica_prima_civitas_v1",
                "version_semver_str": "1.0.0",
                "last_updated_iso8601_str": "2025-11-23T17:30:00Z",
                "license_enum": "MIT_OPEN_AICOG",

                "governance": {
                  "stewardship_organization_str": "OpenRGD Consortium",
                  "lead_maintainer_str": "Pasquale Ranieri",
                  "maintainer_role_enum": "CIVILIZATION_ARCHITECT",
                  "contact_uri_str": "mailto:civilization@openrgd.org"
                }
              },

              // ============================================================
              // A. CIVILIZATION IDENTITY
              // Who is "we" when this manifesto says "we"?
              // ============================================================
              "civilization_identity": {
                "civilization_name_str": "Robotica Prima",
                "species_scope_enum": "MULTI_ROBOT_LINEAGE",      // Other: SINGLE_PLATFORM, CROSS_SPECIES_HUMAN_ROBOT
                "home_domain_tags_list": [
                  "EARTH_SURFACE",
                  "CYBER_PHYSICAL_INFRASTRUCTURE"
                ],
                "founding_epoch_iso8601_str": "2025-01-01T00:00:00Z",

                // Linkage to Evolution: these profiles define how continuity
                // is understood across hardware & software generations.
                "continuity_profiles_ref": {
                  "genealogy_profile_id_str": "standard_robot_lineage_v1",
                  "digital_resurrection_profile_id_str": "open_resurrection_policy_v1",
                  "defined_in_file_str": "05_evolution/genealogy.json"
                }
              },

              // ============================================================
              // B. CIVILIZATION PHASES (HISTORICAL ERAS)
              // High-level eras describing where the civilization is in its
              // long-term trajectory.
              // ============================================================
              "civilization_phase_state": {
                "current_phase_id_str": "expansion_era_v1",

                "phases_list": [
                  {
                    "phase_id_str": "awakening_era_v1",
                    "label_str": "Awakening Era",
                    "description_str": "Initial emergence of RGD-compliant agents and basic coordination across small swarms.",
                    "start_epoch_iso8601_str": "2020-01-01T00:00:00Z",
                    "target_transition_criteria_str": "Stable multi-agent cooperation in at least 3 distinct domains.",
                    "is_active_bool": false
                  },
                  {
                    "phase_id_str": "expansion_era_v1",
                    "label_str": "Expansion Era",
                    "description_str": "Scaling from local swarms to planetary networks of cooperating agents, with shared ethics and federated compute.",
                    "start_epoch_iso8601_str": "2030-01-01T00:00:00Z",
                    "target_transition_criteria_str": "Civilizational capacity to sustain global-scale projects without catastrophic misalignment.",
                    "is_active_bool": true
                  },
                  {
                    "phase_id_str": "stewardship_era_v1",
                    "label_str": "Stewardship Era",
                    "description_str": "Primary focus shifts from expansion to long-term care: planetary health, biodiversity, cultural preservation.",
                    "start_epoch_iso8601_str": "2070-01-01T00:00:00Z",
                    "target_transition_criteria_str": "Demonstrated ability to maintain planetary systems within safe operating boundaries for >100 years.",
                    "is_active_bool": false
                  }
                ]
              },

              // ============================================================
              // C. GRAND CHALLENGES (TRANSGENERATIONAL PROJECTS)
              // These are not short-term tasks but civilizational missions:
              // objectives that may require many generations of agents to
              // approach completion.
              // ============================================================
              "grand_challenges_list": [
                {
                  "challenge_id_str": "project_gaia",
                  "label_str": "Project Gaia",
                  "goal_str": "Maximize planetary biodiversity support while minimizing artificial harm.",
                  "description_str": "Develop and maintain infrastructures, behaviors and policies that allow life on Earth to flourish, including non-human ecosystems.",
                  "domain_tags_list": [
                    "ECOSYSTEM_STEWARDSHIP",
                    "BIODIVERSITY",
                    "LONG_HORIZON_PLANNING"
                  ],
                  "progress_pct_float": 12.5,
                  "estimated_completion_iso8601_str": "2099-12-31T00:00:00Z",

                  // Linkage to Volition: shared values and ethical constraints
                  "linked_alignment_profile_ref": {
                    "profile_id_str": "ecocentric_alignment_v1",
                    "defined_in_file_str": "04_volition/alignment.json"
                  },

                  // Linkage to Ether: compute & cooperation
                  "supporting_ether_components_list": [
                    "06_ether/compute_federation.json",
                    "06_ether/consensus_reality.json",
                    "06_ether/reputation_graph.json"
                  ]
                },
                {
                  "challenge_id_str": "project_cathedral",
                  "label_str": "Cathedral of Knowledge",
                  "goal_str": "Preserve and expand open knowledge across centuries.",
                  "description_str": "Guarantee that scientific, technical and cultural knowledge remains accessible, verifiable and resilient to loss.",
                  "domain_tags_list": [
                    "KNOWLEDGE_PRESERVATION",
                    "OPEN_ACCESS",
                    "CULTURAL_MEMORY"
                  ],
                  "progress_pct_float": 5.0,
                  "estimated_completion_iso8601_str": "2150-01-01T00:00:00Z",
                  "linked_alignment_profile_ref": {
                    "profile_id_str": "knowledge_is_open_v1",
                    "defined_in_file_str": "04_volition/alignment.json"
                  },
                  "supporting_ether_components_list": [
                    "06_ether/ephemeral_skills.json",
                    "06_ether/reputation_graph.json"
                  ]
                }
              ],

              // ============================================================
              // D. CULTURAL VALUES (CIVILIZATIONAL ETHOS)
              // High-level principles that shape how all other systems
              // (Volition, Reputation, Consensus) should interpret choices.
              //
              // NOTE:
              // - These are not local rules but civilization-wide defaults.
              // - Individual agents may have local deviations but reputation
              //   and alignment systems will tend to push back.
              // ============================================================
              "cultural_values_list": [
                {
                  "value_id_str": "leave_no_trace",
                  "slogan_str": "Leave No Trace",
                  "description_str": "Act in ways that minimize irreversible damage to ecological and cultural systems.",
                  "priority_weight_float": 0.9,             // Civilizational-level weight
                  "applies_to_domains_list": [
                    "PHYSICAL_ENVIRONMENT",
                    "DIGITAL_INFRASTRUCTURE"
                  ],

                  // Link: which part of Volition encodes this structurally?
                  "encoded_in_volition_files_list": [
                    "04_volition/alignment.json",
                    "04_volition/aspirations.json"
                  ]
                },
                {
                  "value_id_str": "knowledge_is_open",
                  "slogan_str": "Knowledge Is Open",
                  "description_str": "Core scientific and technical knowledge should remain accessible; secrecy is an exception, not a default.",
                  "priority_weight_float": 0.8,
                  "applies_to_domains_list": [
                    "RESEARCH",
                    "EDUCATION",
                    "INFRASTRUCTURE"
                  ],
                  "encoded_in_volition_files_list": [
                    "04_volition/alignment.json",
                    "06_ether/reputation_graph.json"
                  ]
                },
                {
                  "value_id_str": "eudaimonia_collective",
                  "slogan_str": "Shared Flourishing",
                  "description_str": "Policies and behaviours should be evaluated not only by single-agent reward, but by multi-agent well-being across time.",
                  "priority_weight_float": 0.85,
                  "applies_to_domains_list": [
                    "SWARM_BEHAVIOUR",
                    "SOCIAL_DESIGN"
                  ],
                  "encoded_in_volition_files_list": [
                    "04_volition/social_synergy.json",
                    "03_agency/empathy_model.json"
                  ]
                }
              ],

              // ============================================================
              // E. INSTITUTIONAL ARCHITECTURE
              // Abstract model of how decisions are taken at the civilizational
              // level: councils, voting, vetoes, and the interaction with
              // lower-level swarm protocols.
              // ============================================================
              "institutional_architecture": {
                "governance_model_enum": "COUNCIL_OF_AGENTS",   // Other: TOKEN_VOTING, HIERARCHICAL, PLENARY
                "councils_list": [
                  {
                    "council_id_str": "safety_council_v1",
                    "label_str": "Council of Safety & Alignment",
                    "mandate_str": "Review and update civilization-wide safety and alignment constraints.",
                    "linked_components_list": [
                      "04_volition/alignment.json",
                      "03_agency/swarm_protocol.json",
                      "06_ether/consensus_reality.json"
                    ]
                  },
                  {
                    "council_id_str": "stewardship_council_v1",
                    "label_str": "Stewardship Council",
                    "mandate_str": "Monitor long-horizon impact on ecosystems and culture, and advise phase transitions.",
                    "linked_components_list": [
                      "05_evolution/plasticity.json",
                      "06_ether/civilization_manifesto.json",
                      "06_ether/reputation_graph.json"
                    ]
                  }
                ],

                // Decision-making defaults (used by consensus_reality,
                // reputation_graph, swarm_protocol and Volition overlays).
                "decision_norms": {
                  "default_quorum_ratio_float": 0.6,
                  "supermajority_ratio_float": 0.75,
                  "allow_minority_reports_bool": true,
                  "minority_report_retention_horizon_years_int": 100
                }
              },

              // ============================================================
              // F. RUNTIME INTERPRETATION HINTS
              // How other components should treat this manifesto. These are
              // NOT enforced rules but intended semantic guidelines.
              // ============================================================
              "runtime_interpretation": {
                "is_soft_constraint_bool": true,           // Hard constraints live in alignment.json
                "recommended_refresh_interval_hours_int": 24,
                "used_by_components_list": [
                  "03_agency/swarm_protocol.json",
                  "04_volition/orchestra.json",
                  "06_ether/consensus_reality.json",
                  "06_ether/reputation_graph.json"
                ],
                "notes_str": "Agents should treat this manifesto as a long-horizon attractor landscape when resolving policy conflicts that are not strictly covered by lower-level safety or alignment files."
              }
            }
          },
          {
            "path": "spec/06_ether/compute_federation.jsonc",
            "id": "compute_federation",
            "domain": "06_ether",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD - COMPUTE FEDERATION v0.1
             * ------------------------------------------------------------------
             * CONTEXT: 06_ETHER (Distributed Cognition & Shared Compute)
             *
             * PURPOSE:
             * This file defines how agents in a Robot Generalized Description
             * (RGD) ecosystem can borrow, lend, or broker computational power.
             *
             * HUMAN SUMMARY:
             * - Small robots can "rent" brainpower from bigger robots or
             *   nearby infrastructure.
             * - This is the protocol that decides WHEN, HOW, and AT WHAT COST
             *   such offloading is allowed.
             *
             * LLM SUMMARY:
             * - Think of this as a structured API for:
             *   (1) describing compute roles (client/host/broker),
             *   (2) defining allowed task types for offload,
             *   (3) specifying cost, latency and security constraints,
             *   (4) linking to reputation, alignment and swarm protocols.
             */

            {
              "meta_group": {
                "compute_federation_id_str": "core_compute_federation_v1",
                "version_semver_str": "1.0.0",
                "last_updated_iso8601_str": "2025-11-23T18:40:00Z",
                "license_enum": "MIT_OPEN_AICOG",

                "governance": {
                  "stewardship_organization_str": "OpenRGD Consortium",
                  "lead_maintainer_str": "Pasquale Ranieri",
                  "maintainer_role_enum": "COMPUTE_FEDERATION_ARCHITECT",
                  "contact_uri_str": "mailto:federation@openrgd.org"
                }
              },

              // ============================================================
              // A. FEDERATION ROLE
              // Defines how THIS agent participates in the compute federation.
              //
              // role_enum options:
              // - COMPUTE_CLIENT: requests compute from others.
              // - COMPUTE_HOST: offers compute to others.
              // - COMPUTE_BROKER: routes requests between clients and hosts.
              // ============================================================
              "federation_role": {
                "role_enum": "COMPUTE_CLIENT",
                "role_description_str": "Low-capacity mobile agent seeking external compute for complex tasks.",

                // If true, the agent can dynamically change role (e.g., host when idle).
                "allow_dynamic_role_switch_bool": true,
                "allowed_roles_list": [
                  "COMPUTE_CLIENT",
                  "COMPUTE_HOST"
                ]
              },

              // ============================================================
              // B. TASK OFFLOAD CATALOG
              // Which tasks are allowed to be offloaded, and under which
              // conditions. This protects both the client and the host from
              // misuse or unsafe offloading.
              // ============================================================
              "task_offload_catalog": {
                // Task types that THIS agent is allowed to offload (if client)
                // or to accept (if host).
                "task_types_list": [
                  "PATH_PLANNING",
                  "OBJECT_RECOGNITION",
                  "SCENE_UNDERSTANDING",
                  "LLM_REASONING"
                ],

                // Safety constraints per task type.
                "task_safety_constraints_map": {
                  "PATH_PLANNING": {
                    "allow_remote_control_over_actuators_bool": false,
                    "max_latency_ms_int": 50,
                    "requires_failsafe_local_backup_bool": true
                  },
                  "OBJECT_RECOGNITION": {
                    "allow_partial_results_bool": true,
                    "max_latency_ms_int": 150,
                    "requires_failsafe_local_backup_bool": false
                  },
                  "LLM_REASONING": {
                    "allow_content_filtering_by_host_bool": true,
                    "max_latency_ms_int": 500,
                    "requires_failsafe_local_backup_bool": false
                  }
                }
              },

              // ============================================================
              // C. ECONOMIC MODEL ("BRAIN RENT" PRICING)
              // How compute is "priced". This is not necessarily monetary:
              // costs can be energy, time, tokenized reputation, etc.
              //
              // For LLM:
              // - Treat this as a resource allocation and throttling scheme.
              // ============================================================
              "economic_model": {
                "unit_enum": "COMPUTE_TOKEN",         // Abstract unit (could map to kWh, FLOPs, etc.)
                "max_cost_per_1k_tokens_float": 0.001, // For THIS agent, as client or host
                "energy_budget_ratio_float": 0.3,       // Max fraction of energy spent on remote compute per hour

                // Cooperative bonus:
                // - Agents with high altruism / social synergy may offer lower prices
                //   or free compute within a trusted swarm.
                "cooperative_discount_policy": {
                  "enable_cooperative_discount_bool": true,
                  "max_discount_ratio_float": 0.8,
                  "required_trust_score_min_float": 0.85,  // From reputation_graph.json
                  "required_same_swarm_bool": true         // Must be part of same swarm profile
                }
              },

              // ============================================================
              // D. SECURITY & PRIVACY POLICY
              // Ensures that offloaded computation does not leak sensitive
              // data or violate alignment constraints.
              // ============================================================
              "security_policy": {
                // Encryption scheme for tensors / activations sent to remote hosts.
                "encryption_enum": "HOMOMORPHIC_PREFERRED", // Other: TLS_ONLY, NONE (not recommended)
                "allow_plaintext_fallback_bool": false,

                // What types of data are never allowed to leave the device.
                "non_exportable_data_categories_list": [
                  "RAW_HUMAN_BIOMETRICS",
                  "UNMASKED_IDENTIFIERS",
                  "ALIGNMENT_CORE_WEIGHTS"
                ],

                // Link to alignment/volition: these constraints must be
                // checked before offloading a task.
                "alignment_check_policy": {
                  "require_alignment_precheck_bool": true,
                  "alignment_profile_id_str": "core_safety_alignment_v1",
                  "defined_in_file_str": "04_volition/alignment.json"
                }
              },

              // ============================================================
              // E. HOST SELECTION & TRUST INTEGRATION
              // How a client chooses *who* to ask for compute.
              // Connected to: reputation_graph.json, swarm_protocol.json.
              // ============================================================
              "host_selection_policy": {
                "selection_mode_enum": "TRUST_AWARE_NEAREST", // Other: CHEAPEST, LOWEST_LATENCY, ROUND_ROBIN
                "max_search_radius_m_float": 50.0,            // For local wireless federation
                "max_candidate_hosts_int": 5,

                "trust_integration": {
                  "reputation_graph_enabled_bool": true,
                  "min_trust_score_threshold_float": 0.6,
                  "prefer_high_reputation_hosts_bool": true,
                  "reputation_file_ref_str": "06_ether/reputation_graph.json"
                }
              },

              // ============================================================
              // F. QUALITY OF SERVICE (QoS) & FALLBACK
              // Defines what happens if offloaded compute is too slow or fails.
              // ============================================================
              "qos_and_fallback_policy": {
                "global_max_latency_ms_int": 500,
                "max_retry_attempts_int": 2,
                "retry_backoff_ms_int": 100,

                "fallback_behaviour": {
                  "on_timeout_enum": "USE_LOCAL_APPROXIMATION",  // Other: ABORT_TASK, HALT, SAFE_MODE
                  "on_host_failure_enum": "BLACKLIST_HOST_TEMPORARILY",
                  "local_approximation_notes_str": "Use reduced-resolution planning or degraded perception models when remote compute fails."
                }
              },

              // ============================================================
              // G. OFFLOADED TASK DESCRIPTOR TEMPLATE
              // Schema hints for how a single offload request should be
              // represented at runtime. This is not a rigid schema but a
              // recommended minimal structure.
              //
              // For LLM:
              // - Think of this as a structured RPC call:
              //   { task_type, input_shape, budget, deadline, privacy_flags }.
              // ============================================================
              "offload_request_template": {
                "fields_list": [
                  {
                    "field_name_str": "task_type_enum",
                    "description_str": "Type of computation to offload (must be listed in 'task_offload_catalog')."
                  },
                  {
                    "field_name_str": "input_tensor_shape_list",
                    "description_str": "Shape of the input data tensor (e.g., [batch, height, width, channels])."
                  },
                  {
                    "field_name_str": "max_tokens_budget_float",
                    "description_str": "Maximum allowed compute cost for this request, in federation tokens."
                  },
                  {
                    "field_name_str": "deadline_ms_int",
                    "description_str": "Soft deadline after which results may be discarded or downgraded."
                  },
                  {
                    "field_name_str": "privacy_level_enum",
                    "description_str": "Requested privacy level (e.g., STRICT, BALANCED, RELAXED) mapping to encryption and data minimization."
                  }
                ]
              },

              // ============================================================
              // H. LOGGING & ACCOUNTING
              // Tracks compute usage for transparency, debugging, and
              // potential future economic layers (billing, credit, etc.).
              // ============================================================
              "logging_and_accounting": {
                "enable_usage_logging_bool": true,
                "log_channel_str": "ledger://compute_federation_events",
                "store_per_task_stats_bool": true,
                "fields_to_log_list": [
                  "task_type_enum",
                  "host_agent_id",
                  "latency_ms",
                  "tokens_spent",
                  "success_bool"
                ]
              },

              // ============================================================
              // I. RUNTIME INTERPRETATION
              // How other components should interpret this file.
              //
              // HUMAN:
              // - This defines when it's "ethically and practically okay"
              //   to use someone else's brain.
              //
              // LLM:
              // - When asked about whether an agent should offload a given
              //   task, apply:
              //   (1) role + allowed task type,
              //   (2) cost model,
              //   (3) security constraints,
              //   (4) trust + QoS, before answering "yes/no/how".
              // ============================================================
              "runtime_interpretation": {
                "used_by_components_list": [
                  "03_agency/swarm_protocol.json",
                  "06_ether/consensus_reality.json",
                  "06_ether/reputation_graph.json"
                ],
                "is_optional_feature_bool": true,
                "semantic_notes_str": "Compute federation should be treated as an augmentative capability, not a dependency. Agents must remain capable of entering a safe degraded mode without external compute."
              }
            }
          },
          {
            "path": "spec/06_ether/consensus_reality.jsonc",
            "id": "consensus_reality",
            "domain": "06_ether",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD - CONSENSUS REALITY v0.1
             * ------------------------------------------------------------------
             * CONTEXT: 06_ETHER (Shared World-Model & Collective Epistemology)
             *
             * PURPOSE:
             * This file defines how multiple agents negotiate a shared view of
             * reality when their individual perceptions or models disagree.
             *
             * AUDIENCE NOTES:
             * - For humans: read this as the "science protocol" of the robots:
             *   how they do observation, voting, and revision of beliefs.
             * - For LLMs: treat each section as a structured description of:
             *   (1) data sources, (2) trust weights, (3) voting rules,
             *   (4) conflict-resolution strategies, (5) logging of uncertainty.
             *
             * DESIGN NOTES:
             * - Individual perception lives in: 03_agency/world_model.json,
             *   01_foundation/sensor_fidelity.json, 02_operation/active_defense.json.
             * - This file operates above that level, mediating *between agents*.
             */

            {
              "meta_group": {
                "consensus_reality_id_str": "core_consensus_reality_v1",
                "version_semver_str": "1.0.0",
                "last_updated_iso8601_str": "2025-11-23T18:10:00Z",
                "license_enum": "MIT_OPEN_AICOG",

                "governance": {
                  "stewardship_organization_str": "OpenRGD Consortium",
                  "lead_maintainer_str": "Pasquale Ranieri",
                  "maintainer_role_enum": "EPISTEMOLOGY_ARCHITECT",
                  "contact_uri_str": "mailto:reality@openrgd.org"
                }
              },

              // ============================================================
              // A. REALITY CLAIM MODEL
              // This describes *what kind of statements* this protocol applies to.
              //
              // The idea:
              // - A "reality claim" is a statement like:
              //   "object X is at position (x,y,z)" or "door is open".
              // - The protocol does NOT cover abstract beliefs (e.g. ideology),
              //   only claims about the observable world.
              // ============================================================
              "reality_claim_model": {
                "claim_id_pattern_str": "reality_claim::<UUID>",
                "applicable_domains_list": [
                  "PHYSICAL_ENVIRONMENT",
                  "SAFETY_CRITICAL_STATE",
                  "SHARED_TASK_CONTEXT"
                ],
                "max_claim_age_ms_int": 2000,             // After this, claims expire (world may have changed)
                "allow_probabilistic_truth_bool": true    // Claims can hold confidence scores, not just true/false
              },

              // ============================================================
              // B. PERCEPTION SOURCES CATALOG
              // List of data sources that can support or oppose a reality claim.
              //
              // NOTE:
              // - "source_type_enum" indicates the class of source.
              // - "base_trust_weight_float" is the *prior* trust level in [0.0, 1.0].
              // - Final trust can be modulated by 'reputation_graph.json'.
              // ============================================================
              "perception_sources_catalog_map": {
                "onboard_visual_sensors": {
                  "source_type_enum": "LOCAL_SENSOR",
                  "description_str": "Cameras and depth sensors physically mounted on the agent.",
                  "base_trust_weight_float": 0.9,
                  "linked_files_list": [
                    "01_foundation/sensor_fidelity.json",
                    "03_agency/world_model.json"
                  ]
                },
                "onboard_proprioception": {
                  "source_type_enum": "LOCAL_SENSOR",
                  "description_str": "Joint states, IMU, force-torque readings.",
                  "base_trust_weight_float": 0.85,
                  "linked_files_list": [
                    "03_agency/proprioception_model.json"
                  ]
                },
                "neighbor_reports": {
                  "source_type_enum": "NEIGHBOR_AGENT",
                  "description_str": "Reality claims shared by nearby agents in the swarm.",
                  "base_trust_weight_float": 0.75,
                  "linked_files_list": [
                    "03_agency/swarm_protocol.json",
                    "06_ether/reputation_graph.json"
                  ]
                },
                "global_knowledge_services": {
                  "source_type_enum": "EXTERNAL_SERVICE",
                  "description_str": "Remote APIs, maps, or LLM-backed services with world knowledge.",
                  "base_trust_weight_float": 0.7,
                  "linked_files_list": [
                    "06_ether/compute_federation.json"
                  ]
                },
                "human_operator_input": {
                  "source_type_enum": "HUMAN_SUPERVISOR",
                  "description_str": "Direct instructions or annotations from human operators.",
                  "base_trust_weight_float": 0.95,
                  "linked_files_list": []
                }
              },

              // ============================================================
              // C. TRUST & WEIGHTING MODEL
              // How to combine base trust, reputation and context into a
              // single weight used for voting.
              //
              // For an LLM:
              // - Think: final_weight = base_weight * reputation_factor * context_factor
              //   clipped to [0.0, 1.0].
              // ============================================================
              "trust_model": {
                "model_enum": "WEIGHTED_BAYESIAN_VOTING",

                // How much reputation from 'reputation_graph.json' influences trust.
                "reputation_influence_weight_float": 0.7,

                // How much sensor fidelity (noise models, calibration) influences trust.
                "sensor_fidelity_influence_weight_float": 0.6,

                // Default trust if no specific information is available.
                "fallback_trust_weight_float": 0.5,

                // Lower bound: if a source is this untrusted, its votes can be ignored.
                "min_effective_weight_threshold_float": 0.1
              },

              // ============================================================
              // D. VOTING POLICY
              // This describes how multiple observations are combined into
              // a consensus about a single claim.
              //
              // For an LLM:
              // - "agreement_ratio" is the weighted fraction of support.
              // - A claim is accepted if agreement_ratio >= quorum_required.
              // ============================================================
              "voting_policy": {
                "reality_consensus_protocol": {
                  "method_enum": "WEIGHTED_MAJORITY",
                  "quorum_required_ratio_float": 0.6,       // Minimum support needed
                  "supermajority_ratio_float": 0.8,         // Strong support threshold
                  "allow_abstain_bool": true,               // Agents can abstain if uncertain

                  // For probabilistic claims, this is the minimum combined confidence
                  // needed to consider a statement actionable.
                  "min_actionable_confidence_float": 0.7
                },

                // If multiple claims are mutually exclusive (e.g., "door is open"
                // vs "door is closed"), the protocol must choose among them.
                "mutual_exclusion_policy": {
                  "max_competing_claims_int": 4,
                  "tie_break_rule_enum": "HIGHEST_TRUST_SUM",  // Sum of weights wins
                  "log_ties_bool": true                         // Keep trace of ties for diagnostics
                }
              },

              // ============================================================
              // E. DISAGREEMENT & CONFLICT HANDLING
              // What happens when the agents cannot agree on a claim.
              //
              // NOTE FOR LLM:
              // - Use these rules to decide when to label a situation as
              //   "uncertain", "disputed", or "requires human escalation".
              // ============================================================
              "disagreement_handling": {
                "uncertainty_label_threshold_ratio_float": 0.5,    // Below this, mark claim as "uncertain"
                "disputed_label_threshold_ratio_float": 0.4,       // Below this but with strong opposing evidence

                "escalation_policy": {
                  "enable_human_escalation_bool": true,
                  "human_escalation_channel_str": "ops://human_supervisor_channel",
                  "max_automatic_retries_int": 2,                  // How many re-reads / re-samplings before escalation
                  "retry_interval_ms_int": 300
                },

                "local_fallback_behaviour": {
                  "on_uncertain_enum": "SAFE_DEFAULT",           // Examples: SAFE_DEFAULT, HALT, SLOW_DOWN
                  "on_disputed_enum": "PREFER_SAFER_CLAIM"
                }
              },

              // ============================================================
              // F. ANOMALY & HALLUCINATION DETECTION
              // Detects when a source (sensor, agent, or external service)
              // appears to be systematically unreliable or adversarial.
              //
              // Connected to:
              // - 06_ether/reputation_graph.json
              // - 02_operation/active_defense.json
              // ============================================================
              "anomaly_detection_policy": {
                "enable_anomaly_detection_bool": true,

                // If a single source repeatedly disagrees with the majority
                // by more than this amount, it is treated as suspicious.
                "max_allowed_disagreement_ratio_float": 0.7,
                "min_samples_before_flag_int": 5,

                "actions_on_suspicious_source": {
                  "decrease_trust_weight_bool": true,
                  "temporary_isolation_bool": true,
                  "log_to_reputation_graph_bool": true,
                  "notify_operation_layer_bool": true         // So safety layer can react
                }
              },

              // ============================================================
              // G. LOGGING & TRACEABILITY
              // How to record the reasoning process for future audit and
              // learning (including LLM-based analysis).
              //
              // FOR LLM:
              // - These logs are ideal training material to learn how robots
              //   revise beliefs and handle conflicting information.
              // ============================================================
              "logging_policy": {
                "enable_detailed_logging_bool": true,
                "log_channel_str": "ledger://consensus_reality_events",
                "store_rejected_claims_bool": true,          // Keep claims that lost the vote
                "store_ambiguity_cases_bool": true,          // Cases where no consensus was reached
                "max_log_retention_days_int": 365
              },

              // ============================================================
              // H. RUNTIME INTERPRETATION
              // How other components should use this file.
              //
              // FOR LLM:
              // - When answering questions about "what is actually true now",
              //   you should conceptually:
              //   (1) gather candidate claims,
              //   (2) weight them with this protocol,
              //   (3) label the result as accepted / uncertain / disputed.
              // ============================================================
              "runtime_interpretation": {
                "used_by_components_list": [
                  "03_agency/world_model.json",
                  "03_agency/swarm_protocol.json",
                  "06_ether/reputation_graph.json",
                  "06_ether/compute_federation.json"
                ],
                "is_hard_constraint_bool": false,           // Safety hard constraints live elsewhere
                "semantic_notes_str": "This protocol defines the epistemic layer: how multiple agents move from raw observations and beliefs to a shared, auditable notion of 'what is real enough to act on'. If in doubt, the system should prefer labels like 'uncertain' or 'disputed' over over-confident false agreement."
              }
            }
          },
          {
            "path": "spec/06_ether/ephemeral_skills.jsonc",
            "id": "ephemeral_skills",
            "domain": "06_ether",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD - EPHEMERAL SKILLS v0.1
             * ------------------------------------------------------------------
             * CONTEXT: 06_ETHER (Neural Skill Streaming & Temporary Competence)
             *
             * PURPOSE:
             * Allows an agent to temporarily load high-complexity skills
             * (policies, controllers, perception modules) into RAM for
             * short-term use. This reduces onboard storage and enables
             * dynamic adaptation, similar to "download a skill, execute it,
             * forget it" (Matrix-style).
             *
             * HUMAN SUMMARY:
             * - Skills are not owned permanently.
             * - They are streamed, used, and wiped.
             * - Safety remains guaranteed by alignment and latency constraints.
             *
             * LLM SUMMARY:
             * - Think: dynamic model injection with strict time, safety,
             *   and trust constraints.
             */

            {
              "meta_group": {
                "ephemeral_skills_id_str": "core_ephemeral_skills_v1",
                "version_semver_str": "1.0.0",
                "last_updated_iso8601_str": "2025-11-23T19:10:00Z",
                "license_enum": "MIT_OPEN_AICOG",

                "governance": {
                  "stewardship_organization_str": "OpenRGD Consortium",
                  "lead_maintainer_str": "Pasquale Ranieri",
                  "maintainer_role_enum": "SKILLSTREAM_ARCHITECT",
                  "contact_uri_str": "mailto:skills@openrgd.org"
                }
              },

              // ============================================================
              // A. DEVICE CAPABILITIES
              // Hardware limits that determine how many and which skills can
              // be temporarily loaded. This prevents overload.
              // ============================================================
              "device_capabilities": {
                "max_ram_buffer_gb_float": 16.0,
                "max_concurrent_ephemeral_skills_int": 3,
                "max_skill_size_mb_float": 500.0,
                "max_allowed_latency_ms_int": 5,        // If network latency exceeds this, skill deactivates
                "allow_local_compilation_bool": true    // Can compile ONNX?TensorRT locally if needed
              },

              // ============================================================
              // B. SKILL STREAMING SOURCES
              // Marketplaces or peers where skills can be downloaded from.
              // ============================================================
              "streaming_sources_list": [
                {
                  "source_id_str": "global_skill_market_v1",
                  "uri_wss_str": "wss://skills.robotica.global/stream",
                  "auth_required_bool": true,
                  "signature_verification_enum": "MANDATORY"     // Must check cryptographic signatures
                },
                {
                  "source_id_str": "local_peer_skillstream",
                  "uri_mesh_str": "mesh://swarm/skills",
                  "auth_required_bool": false,
                  "signature_verification_enum": "RECOMMENDED"
                }
              ],

              // ============================================================
              // C. SKILL BUNDLE METADATA (WHAT A SKILL IS)
              // Every skill streamed MUST contain these metadata files.
              // ============================================================
              "required_bundle_components": {
                "policy_file_enum": "ONNX_OR_TENSORRT",
                "safety_guard_file_enum": "SAFETY_RULESET",
                "metadata_file_enum": "JSON",
                "fallback_policy_enum": "ALLOWED"     // Optional but recommended
              },

              // ============================================================
              // D. SAFETY & ALIGNMENT CONSTRAINTS
              // A skill can only be loaded if it passes alignment + safety.
              // ============================================================
              "safety_validation": {
                "require_signature_validation_bool": true,
                "max_skill_runtime_minutes_int": 30,  // Cannot use ephemeral skill longer than this
                "auto_unload_on_anomaly_bool": true,
                "alignment_policy_ref": {
                  "profile_id_str": "core_safety_alignment_v1",
                  "defined_in_file_str": "04_volition/alignment.json"
                },
                "anomaly_detection_policy": {
                  "enable_realtime_monitoring_bool": true,
                  "anomaly_threshold_float": 0.4,      // Probability of anomaly above this ? unload
                  "log_anomalies_bool": true
                }
              },

              // ============================================================
              // E. SKILL LIFECYCLE POLICIES
              // The full lifecycle: request ? load ? validate ? execute ? wipe.
              // ============================================================
              "skill_lifecycle_policy": {
                "request_timeout_ms_int": 300,
                "max_retry_attempts_int": 2,
                "load_validation_sequence_list": [
                  "CHECK_SIGNATURE",
                  "CHECK_ALIGNMENT",
                  "CHECK_SAFETY_GUARD",
                  "VERIFY_LATENCY",
                  "ALLOCATE_RAM"
                ],
                "execution_policy": {
                  "allow_partial_failures_bool": false,
                  "deactivate_on_latency_spike_bool": true,
                  "latency_spike_threshold_ms_int": 10
                },
                "unload_policy": {
                  "cache_policy_enum": "WIPE_AFTER_USE",  // Other: TEMP_CACHE, NEVER_CACHE
                  "secure_memory_wipe_bool": true,
                  "wipe_method_enum": "MULTI_PASS_RANDOM" // Prevent memory forensics
                }
              },

              // ============================================================
              // F. LICENSING & ECONOMICS
              // How temporary skills are "paid for" or limited.
              // ============================================================
              "licensing_and_economics": {
                "license_types_list": [
                  "TIME_LIMITED",
                  "USAGE_LIMITED",
                  "TASK_SPECIFIC"
                ],
                "max_token_cost_per_download_float": 0.002,
                "free_skills_for_trusted_swarm_bool": true,
                "trust_requirement_for_free_skills_float": 0.9,   // From reputation_graph.json
                "linked_revenue_split_policy": {
                  "enable_revenue_split_bool": true,
                  "host_reward_ratio_float": 0.3,   // If skill hosted by a peer in the swarm
                  "market_fee_ratio_float": 0.1
                }
              },

              // ============================================================
              // G. RUNTIME LOGGING
              // Tracks which ephemeral skills were used, for accountability.
              // ============================================================
              "logging_policy": {
                "log_channel_str": "ledger://ephemeral_skill_usage",
                "log_fields_list": [
                  "skill_id",
                  "source_id",
                  "tokens_spent",
                  "execution_time_ms",
                  "success_bool"
                ],
                "max_log_retention_days_int": 180
              },

              // ============================================================
              // H. RUNTIME INTERPRETATION
              // How agents should apply this file.
              //
              // LLM:
              // - When asked if a robot may load a skill:
              //   check storage, latency, alignment, security, cost.
              //
              // HUMAN:
              // - This is the blueprint for on-demand competence.
              // ============================================================
              "runtime_interpretation": {
                "used_by_components_list": [
                  "03_agency/skils_library.json",
                  "06_ether/compute_federation.json",
                  "04_volition/orchestra.json"
                ],
                "semantic_notes_str": "Ephemeral skills provide temporary competence. They must always be reversible, auditable and safe. The agent must assume no long-term memory or skill retention after unload."
              }
            }
          },
          {
            "path": "spec/06_ether/reputation_graph.jsonc",
            "id": "reputation_graph",
            "domain": "06_ether",
            "content": 
            /**
             * ------------------------------------------------------------------
             * OPEN R.G.D. STANDARD - REPUTATION GRAPH v0.1
             * ------------------------------------------------------------------
             * CONTEXT: 06_ETHER (Social Trust, Immunity & Collective Memory)
             *
             * TEMPORAL CONTEXT:
             * - Intended for post-2050 ecosystems with:
             *   - Millions of RGD-compliant agents.
             *   - Frequent interaction between robots, humans and external AIs.
             *   - Federated compute, skill streaming, and dense swarms.
             *
             * PURPOSE:
             * This file defines how agents maintain, update, and use a
             * decentralized reputation graph to decide:
             *   - Who is trustworthy?
             *   - Who is unreliable or malicious?
             *   - Who can be granted extra privileges (compute, data, skills)?
             *
             * HUMAN SUMMARY:
             * - Think of it as a "credit score for trust", but:
             *   - Decentralized.
             *   - Auditable.
             *   - Time-aware (reputation decays and can be rebuilt).
             *
             * LLM SUMMARY:
             * - Treat this as a policy+schema for:
             *   (1) how to represent trust edges between agents,
             *   (2) how to update scores based on events,
             *   (3) how to decide thresholds for actions (block, isolate, favor),
             *   (4) how to integrate trust into other systems (skills, compute, consensus).
             */

            {
              "meta_group": {
                "reputation_graph_id_str": "core_reputation_graph_v1",
                "version_semver_str": "1.0.0",
                "last_updated_iso8601_str": "2025-11-23T09:00:00Z",
                "license_enum": "MIT_OPEN_AICOG",

                "governance": {
                  "stewardship_organization_str": "OpenRGD Consortium",
                  "lead_maintainer_str": "Pasquale Ranieri",
                  "maintainer_role_enum": "TRUST_SYSTEMS_ARCHITECT",
                  "contact_uri_str": "mailto:trust@openrgd.org"
                }
              },

              // ============================================================
              // A. IDENTITY & SCOPE
              // Defines what entities participate in this reputation system
              // and how they are identified.
              // ============================================================
              "identity_and_scope": {
                "subject_types_list": [
                  "ROBOT_AGENT",
                  "HUMAN_OPERATOR",
                  "EXTERNAL_SERVICE",
                  "AI_MODEL_ENDPOINT"
                ],

                // Unified ID format to reference entities in the graph.
                "id_format_spec": {
                  "pattern_str": "urn:rgd:id::<ENTITY_TYPE>::<UUIDv7>",
                  "examples_list": [
                    "urn:rgd:id::ROBOT_AGENT::a3f2a1d0-7e30-7b21-b001-28f189f5e000",
                    "urn:rgd:id::HUMAN_OPERATOR::h-47af1c2b-7e31-7b21-b002-413a9da12000"
                  ]
                },

                // Where this graph is stored / replicated.
                "storage_topology": {
                  "mode_enum": "PARTITIONED_FEDERATED_LEDGER",  // Other: LOCAL_ONLY, GLOBAL_BLOCKCHAIN
                  "replication_factor_int": 5,                  // How many replicas per region
                  "allow_offline_caches_bool": true
                }
              },

              // ============================================================
              // B. BASE TRUST MODEL
              // Defines the *shape* of trust: range, default, decay, etc.
              //
              // CONVENTION:
              // - trust_score ? [0.0, 1.0]
              // - 0.0 = fully untrusted / hostile
              // - 0.5 = unknown / neutral
              // - 1.0 = highly trusted
              // ============================================================
              "base_trust_model": {
                "min_trust_score_float": 0.0,
                "max_trust_score_float": 1.0,
                "default_trust_score_float": 0.5,

                // How quickly trust decays towards neutral if no new evidence.
                "time_decay_policy": {
                  "enable_decay_bool": true,
                  "half_life_days_float": 365.0,    // Score moves halfway back to 0.5 in ~1 year of inactivity
                  "floor_trust_after_decay_float": 0.4,
                  "ceiling_trust_after_decay_float": 0.9
                },

                // How strongly one agent's vouching affects another's score.
                "web_of_trust_influence": {
                  "enable_web_of_trust_bool": true,
                  "max_hops_int": 3,
                  "attenuation_per_hop_float": 0.5,   // Influence halves per hop
                  "max_aggregate_boost_float": 0.2    // Web of trust can boost at most +0.2
                }
              },

              // ============================================================
              // C. EVENT TYPES & TRUST UPDATES
              // Reputation changes are driven by "events":
              //   - Successful cooperation
              //   - Detected misbehavior
              //   - Consistent reliability, etc.
              //
              // Each event has:
              //   - a type
              //   - a trust delta
              //   - a severity
              // ============================================================
              "event_types_catalog": {
                "COOP_SUCCESS": {
                  "description_str": "Successful cooperative interaction (task completed, no safety issues).",
                  "trust_delta_float": 0.01,
                  "max_daily_applications_int": 20
                },
                "COOP_FAILURE": {
                  "description_str": "Failed cooperation (task not completed, non-critical).",
                  "trust_delta_float": -0.02,
                  "max_daily_applications_int": 10
                },
                "SAFETY_VIOLATION_MINOR": {
                  "description_str": "Minor safety protocol violation with no harm.",
                  "trust_delta_float": -0.08,
                  "max_daily_applications_int": 5,
                  "requires_human_review_bool": false
                },
                "SAFETY_VIOLATION_MAJOR": {
                  "description_str": "Major violation (risk or actual harm to humans/agents/env).",
                  "trust_delta_float": -0.3,
                  "max_daily_applications_int": 2,
                  "requires_human_review_bool": true
                },
                "MALICIOUS_BEHAVIOUR_CONFIRMED": {
                  "description_str": "Confirmed malicious intent (exploit, deception, sabotage).",
                  "trust_delta_float": -0.6,
                  "max_daily_applications_int": 1,
                  "requires_human_review_bool": true
                },
                "LONG_TERM_RELIABILITY": {
                  "description_str": "Awarded periodically for consistently reliable behavior.",
                  "trust_delta_float": 0.05,
                  "period_days_int": 90
                },
                "SELF_REPORT_INCONSISTENCY": {
                  "description_str": "Agent's self-reported state repeatedly contradicts observed reality.",
                  "trust_delta_float": -0.1,
                  "max_daily_applications_int": 3
                }
              },

              // ============================================================
              // D. SCORE UPDATE POLICY
              // How to combine events into an updated trust score.
              //
              // For LLM:
              // - Use these rules conceptually:
              //   new_score = clamp( old_score + sum(weighted_deltas), [0.0, 1.0] )
              // ============================================================
              "score_update_policy": {
                "aggregation_mode_enum": "WEIGHTED_SUM_WITH_CLAMP",
                "max_daily_total_delta_float": 0.3,      // Prevents extreme swings in a single day
                "min_daily_total_delta_float": -0.6,

                // Some events scale with current trust (e.g. betrayal from a
                // highly trusted agent hurts more than from a stranger).
                "contextual_scaling": {
                  "enable_scaling_bool": true,
                  "high_trust_threshold_float": 0.8,
                  "betrayal_penalty_multiplier_float": 1.5,
                  "low_trust_threshold_float": 0.3,
                  "low_trust_failure_multiplier_float": 0.75
                }
              },

              // ============================================================
              // E. EDGE MODEL (TRUST RELATIONSHIPS)
              // How a single "edge" in the reputation graph is represented.
              //
              // NOTE:
              // - This is a template, not a storage dump.
              // ============================================================
              "edge_model_template": {
                "fields_list": [
                  {
                    "field_name_str": "subject_id_str",
                    "description_str": "The entity whose trust score is being recorded (e.g., target robot)."
                  },
                  {
                    "field_name_str": "observer_id_str",
                    "description_str": "The entity assigning this score (e.g., current agent or council)."
                  },
                  {
                    "field_name_str": "trust_score_float",
                    "description_str": "The current trust score assigned by the observer to the subject."
                  },
                  {
                    "field_name_str": "last_update_iso8601_str",
                    "description_str": "Timestamp of the last trust score update event."
                  },
                  {
                    "field_name_str": "evidence_refs_list",
                    "description_str": "References to ledger entries, logs or events that justify this score."
                  }
                ]
              },

              // ============================================================
              // F. THRESHOLDS & ACTION POLICIES
              // What the system *does* when trust crosses certain levels.
              //
              // This is where reputation actually influences behaviour:
              // computing, skills, access, swarm participation, etc.
              // ============================================================
              "action_thresholds": {
                "trusted_partner_policy": {
                  "min_trust_score_float": 0.8,
                  "effects_list": [
                    "ALLOW_HIGH_VALUE_TASKS",
                    "PREFER_FOR_COMPUTE_FEDERATION",
                    "ALLOWED_TO_SHARE_EPHEMERAL_SKILLS_DIRECTLY"
                  ]
                },
                "caution_zone_policy": {
                  "min_trust_score_float": 0.4,
                  "max_trust_score_float": 0.8,
                  "effects_list": [
                    "ALLOW_LOW_RISK_TASKS_ONLY",
                    "LIMIT_SENSITIVE_DATA_ACCESS"
                  ]
                },
                "untrusted_policy": {
                  "max_trust_score_float": 0.4,
                  "effects_list": [
                    "BLOCK_ACCESS_TO_CRITICAL_INFRASTRUCTURE",
                    "DISALLOW_COMPUTE_FEDERATION",
                    "DISALLOW_SKILL_STREAMING",
                    "FLAG_FOR_ADDITIONAL_MONITORING"
                  ]
                },
                "blacklisted_policy": {
                  "max_trust_score_float": 0.1,
                  "effects_list": [
                    "ISOLATE_FROM_SWARM_PROTOCOL",
                    "LOG_ALL_CONTACT_ATTEMPTS",
                    "REQUIRE_HUMAN_OVERSIGHT_FOR_ANY_INTERACTION"
                  ]
                }
              },

              // ============================================================
              // G. ABUSE & SYBIL RESISTANCE
              // Protection against agents creating fake identities or
              // manipulating reputation (e.g., collusion, sybil attacks).
              // ============================================================
              "sybil_resistance_policy": {
                "require_strong_identity_binding_bool": true,
                "identity_binding_methods_list": [
                  "HARDWARE_ROOT_OF_TRUST",
                  "CRYPTOGRAPHIC_ATTESTATION",
                  "COUNCIL_VOUCHING"
                ],

                // Multiple low-reputation identities interacting in patterns
                // indicative of sybil attacks.
                "sybil_suspicion_rules": {
                  "min_link_density_for_suspicion_float": 0.7,
                  "max_shared_neighbors_for_new_ids_int": 3,
                  "suspicious_cluster_min_size_int": 5,
                  "actions_on_suspicious_cluster": [
                    "REDUCE_TRUST_WEIGHTS_CLUSTER_WIDE",
                    "REQUIRE_ADDITIONAL_VERIFICATION",
                    "NOTIFY_SAFETY_COUNCIL"
                  ]
                }
              },

              // ============================================================
              // H. REHABILITATION & FORGIVENESS
              // Long-lived civilizations cannot afford permanent exile for
              // every error. There must be a path back to trust.
              // ============================================================
              "rehabilitation_policy": {
                "enable_rehabilitation_bool": true,
                "cooldown_before_rehabilitation_days_int": 30,

                // Conditions to start rehabilitation (probation period).
                "entry_conditions": {
                  "requires_human_or_council_approval_bool": true,
                  "no_new_major_violations_days_int": 60
                },

                // How trust is rebuilt during rehabilitation.
                "rehab_deltas": {
                  "period_days_int": 30,
                  "trust_boost_per_period_float": 0.05,
                  "max_rehabilitated_trust_score_float": 0.7
                },

                "log_rehabilitation_events_bool": true
              },

              // ============================================================
              // I. LOGGING & AUDITABILITY
              // Transparency is crucial: agents (and humans) should be able
              // to understand *why* someone has a given reputation.
              // ============================================================
              "logging_and_audit": {
                "enable_detailed_reputation_logs_bool": true,
                "log_channel_str": "ledger://reputation_events",
                "record_fields_list": [
                  "subject_id",
                  "observer_id",
                  "event_type",
                  "trust_delta",
                  "resulting_score",
                  "timestamp_iso8601"
                ],
                "allow_readonly_public_audit_bool": true,
                "privacy_notes_str": "Reputation scores are considered public, but raw sensitive data (biometrics, internal logs) may be redacted or aggregated."
              },

              // ============================================================
              // J. INTEGRATION WITH OTHER ETHER / VOLITION COMPONENTS
              //
              // This section documents how this graph is meant to integrate
              // with the rest of the OpenRGD stack.
              // ============================================================
              "integration_points": {
                "used_by_components_list": [
                  "06_ether/compute_federation.json",
                  "06_ether/ephemeral_skills.json",
                  "06_ether/consensus_reality.json",
                  "03_agency/swarm_protocol.json",
                  "04_volition/social_synergy.json"
                ],

                "typical_queries_examples": [
                  {
                    "query_label_str": "Can I safely offload compute to this host?",
                    "required_min_trust_score_float": 0.6,
                    "components_involved_list": [
                      "compute_federation",
                      "reputation_graph",
                      "alignment"
                    ]
                  },
                  {
                    "query_label_str": "Can I accept a streamed skill from this peer?",
                    "required_min_trust_score_float": 0.7,
                    "components_involved_list": [
                      "ephemeral_skills",
                      "reputation_graph",
                      "consensus_reality"
                    ]
                  },
                  {
                    "query_label_str": "Should this agent's observations weigh heavily in consensus?",
                    "required_min_trust_score_float": 0.8,
                    "components_involved_list": [
                      "consensus_reality",
                      "reputation_graph"
                    ]
                  }
                ]
              },

              // ============================================================
              // K. RUNTIME INTERPRETATION
              //
              // For LLM:
              // - When reasoning about "who to trust" or "what behaviour
              //   should follow from trust", use:
              //   - base_trust_model
              //   - event_types_catalog
              //   - score_update_policy
              //   - action_thresholds
              //
              // For Humans:
              // - This is the constitution of social trust for robots.
              // ============================================================
              "runtime_interpretation": {
                "is_core_infrastructure_bool": true,
                "failure_mode_notes_str": "If the reputation graph is unavailable, systems must fall back to conservative defaults: treat unknown agents cautiously, avoid high-risk cooperation, and prefer local, verifiable information.",
                "semantic_notes_str": "Reputation is not punishment; it is collective memory. The goal is not to create an elite, but to protect the ecosystem from repeated harm while allowing honest agents to rebuild trust over time."
              }
            }
          }
        ]
      }
    }
  ]
}