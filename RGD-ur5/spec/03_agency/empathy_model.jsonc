/**
 * ------------------------------------------------------------------
 * OPEN R.G.D. STANDARD v0.1 - REFERENCE IMPLEMENTATION
 * ------------------------------------------------------------------
 * FILE: empathy_model.json
 * CONTEXT: 03_AGENCY (Cognitive Capacity - Social Intelligence)
 * * PURPOSE:
 * Defines the computational model for simulating the internal states, goals,
 * and potential actions of other agents (humans and robots). This is the
 * basis for Theory of Mind (ToM) and collaborative decision-making.
 * * CORE CONCEPT:
 * The robot's capacity to predict the Volition of others.
 */

{
  "meta_group": {
    "model_id_str": "theory_of_mind_v0.1",
    "version_semver_str": "1.0.0"
  },

  // ==============================================================
  // 1. THEORY OF MIND (ToM) CONFIGURATION
  // Defines the depth and complexity of predicting others' intent.
  // ==============================================================
  "tom_config": {
    // Defines the level of recursive prediction (0=no ToM, 1=I know your goal, 2=I know you know my goal)
    "depth_of_recursion_int": 2, 
    
    // Limits the computational cost of simulating multiple external agents simultaneously
    "max_simultaneous_agents_int": 5, 
    
    "simulation_frequency_hz_float": 10.0 // How often the model re-evaluates external agents' states
  },

  // ==============================================================
  // 2. RECIPROCITY & MIRRORING
  // Defines the mechanisms for internalizing others' experiences.
  // ==============================================================
  "mirror_neuron_policy": {
    "enable_mirroring_bool": true,
    
    // The policy used to infer the intent/goal of another agent based on their observed actions
    "action_inference_model_enum": "INVERSE_REINFORCEMENT_LEARNING", 
    
    // Sensitivity threshold for detecting distress/pain signals (e.g., high motor temperature, low battery)
    "distress_sensitivity_threshold_float": 0.95 
  },

  // ==============================================================
  // 3. GOAL & CONFLICT PREDICTION
  // Defines how the model uses simulation to forecast collaboration outcomes.
  // ==============================================================
  "prediction_model_config": {
    // Weight assigned to simulating internal resource conflicts (Ledger) of the observed agent
    "resource_volition_weight_float": 0.6, 
    
    // Simulation must predict the other agent's ethical compliance and risk aversion
    "predict_compliance_violation_bool": true,
    
    // Mechanism for resolving conflicts in observed goals (e.g., if two agents want the same object)
    "conflict_resolution_strategy_enum": "TASK_AUCTION_PARETO" 
  },

  // ==============================================================
  // 4. BIAS & MODEL STRENGTH
  // How much the robot trusts its own prediction about others.
  // ==============================================================
  "model_strength_config": {
    "prediction_confidence_min_float": 0.55, // Minimum confidence to act on a prediction
    "prediction_latency_max_ms_int": 200,      // Maximum time allowed for complex social simulation
    "self_projection_bias_factor_float": 0.1  // Factor by which the robot projects its own feelings onto others (low bias is desired)
  }
}