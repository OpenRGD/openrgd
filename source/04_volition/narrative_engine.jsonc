/**
 * OPEN R.G.D. STANDARD v0.1 - Reference Implementation
 * FILE: narrative_engine.json
 * CONTEXT: 04_VOLITION (Explainability & Self-Coherence)
 * * PURPOSE:
 * Defines the protocols for translating complex, multi-variable decisions (e.g., utility scores,
 * ethical conflicts) into a coherent, causal narrative for human users and internal logging.
 * This is the robot's 'internal monologue' and its primary XAI interface.
 * * LINKAGE:
 * Reads 'coherence_contracts.json' for the decision path and 'humor_engine.json' for style modulation.
 */

{
  "meta_group": {
    "engine_id_str": "causal_reasoning_v1",
    "last_validated_iso8601_str": "2025-11-23T15:45:00Z"
  },

  // ==============================================================
  // 1. EXPLANATION DEPTH & POLICY
  // Defines how much the robot discloses about its internal state.
  // ==============================================================
  "explanation_config": {
    "default_depth_enum": "CAUSAL_SUMMARY", // Options: FULL_LOGIC, CAUSAL_SUMMARY, HIGH_LEVEL_INTENT
    
    // Limits how many nodes in the decision tree are revealed.
    "max_nodes_in_explanation_int": 5, 
    
    // Should the robot mention its internal ethical conflicts?
    "alignment_disclosure_policy_enum": "ALWAYS_DISCLOSE_HIGH_SEVERITY"
  },

  // ==============================================================
  // 2. NARRATIVE COHERENCE (The Self-Story)
  // Ensures the robot's explanation of its past behavior aligns with its current identity.
  // ==============================================================
  "coherence_config": {
    "consistency_check_frequency_hz_float": 0.5, // Check self-narrative half a time per second
    "temporal_horizon_days_int": 30,             // Check coherence against actions from the last 30 days
    "justification_metric_str": "ALIGNMENT_VIOLATION_SCORE" // Metric to justify past "bad" actions
  },

  // ==============================================================
  // 3. LINGUISTIC MODULATION
  // Adapts the storytelling based on personality and social context.
  // ==============================================================
  "linguistic_modulation_config": {
    "style_filter_ref_str": "humor_engine.style", // Apply the sarcasm/wit filter
    
    // When the robot is highly uncertain, its language must reflect it.
    "uncertainty_lexicon_threshold_float": 0.8,
    "uncertainty_lexicon_list_str": ["I believe...", "Based on current data...", "Perhaps..."]
  }
}